<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-TW">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="world4jason" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="菜鳥搬磚日常">
<meta property="og:type" content="website">
<meta property="og:title" content="world4jason">
<meta property="og:url" content="https://world4jason.github.io/page/3/index.html">
<meta property="og:site_name" content="world4jason">
<meta property="og:description" content="菜鳥搬磚日常">
<meta property="og:locale" content="zh-TW">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="world4jason">
<meta name="twitter:description" content="菜鳥搬磚日常">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://world4jason.github.io/page/3/"/>





  <title> world4jason </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-TW">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">world4jason</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">菜鳥搬磚日常</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/31/ICNET code Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/31/ICNET code Analysis/" itemprop="url">
                  ICNET code Analysis
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-31T14:21:27+08:00">
                2018-01-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Code/" itemprop="url" rel="index">
                    <span itemprop="name">Code</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/" itemprop="url">
                  ICNET for Real-Time Semantic Segmentation on High-Resolution Images
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-28T16:50:31+08:00">
                2018-01-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Segmentation/" itemprop="url" rel="index">
                    <span itemprop="name">Segmentation</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h2><p>Quote:<br>其實很討厭這作者的paper<br>效果都很好, 但是每次都是用matlab, 而且PSPNet作者還說training code因為公司問題不能發布, 傻眼<br><img src="/media/15172367977860.jpg" alt=""><br><a href="https://www.zhihu.com/question/53356671" target="_blank" rel="external">https://www.zhihu.com/question/53356671</a></p>
<p>Paper<br><a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1704.08545.pdf</a><br>Code<br><a href="https://github.com/hszhao/ICNet" target="_blank" rel="external">https://github.com/hszhao/ICNet</a><br><a href="https://github.com/aitorzip/Keras-ICNet" target="_blank" rel="external">https://github.com/aitorzip/Keras-ICNet</a><br><a href="https://github.com/hellochick/ICNet-tensorflow" target="_blank" rel="external">https://github.com/hellochick/ICNet-tensorflow</a></p>
<p>Key Difference<br>之前的那些方法，如FCN、SegNet、UNet、RefineNet等，用高解析度圖片當input以後，強調Single scale或是Multi Scale在不同層之間的特徵融合，所有的Data需要在整個網絡中運行，因為高解析度的輸入而導致了昂貴的計算費用.而本文的方法，使用低解析度圖片作為主要輸入，採用高解析度圖片進行refine，保留細節的同時減少了開銷.</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><figure class="highlight armasm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">We</span> propose an compressed-PSPNet-<span class="keyword">based </span>image cascade network (ICNet) that incorporates <span class="keyword">multi-resolution </span><span class="keyword">branches </span>under proper label guidance to <span class="keyword">address </span>this challenge.</div></pre></td></tr></table></figure>
<p>ICNet是一個基於PSPNet的real-time semantic segmentation network，論文內對PSPNet做深入的分析，並且找出影響inference speed*的缺點。並且用搭配multi-resolution cascade combination。</p>
<p>*註:inference speed是單指DeConv的階段。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="/media/15172162210529.png" alt=""></p>
<p>在論文發表的時刻(2017 March), CityScapes上所有的Model表現基本上分成兩種類型, 一種是擁有高精準度但速度不行, 另一種是速度快但精准度不行。此論文在PSPNet的基礎上來增進速度，並找一個速度跟精準度的平衡點。</p>
<p>論文貢獻:</p>
<ul>
<li>可以在1024x2048的解析度下保持30 fps的計算速度(Tensorflow版本實測可行, 但要去掉preproccess部分)</li>
<li>相對PSPNet來說, 可疑提高5倍速度並可以減少五倍RAM消耗</li>
<li>低解析的速度+高解析的細節做cascade的整合</li>
</ul>
<h2 id="Speed-Analysis"><a href="#Speed-Analysis" class="headerlink" title="Speed Analysis"></a>Speed Analysis</h2><p>從PSPNet做解析<br><img src="/media/15172351270369.png" alt=""><br>藍色是1024x2048, 綠色是512x1024 (1/4大小)<br>從上圖可知</p>
<ul>
<li>圖越大速度越慢</li>
<li>網路寬度越大速度越慢</li>
<li>Kernel越多速度越慢, 以圖中例子來說stage4跟stage5在解析同樣的input時, inference speed差距十分驚人, 因為這部分的kernel number差距了一倍。</li>
</ul>
<h2 id="Intuitive-Speedup"><a href="#Intuitive-Speedup" class="headerlink" title="Intuitive Speedup"></a>Intuitive Speedup</h2><h4 id="加速方法-1-輸入向下採樣-Downsampling-Input"><a href="#加速方法-1-輸入向下採樣-Downsampling-Input" class="headerlink" title="加速方法 1: 輸入向下採樣(Downsampling Input)"></a>加速方法 1: 輸入向下採樣(Downsampling Input)</h4><p>在resolution只有原本的0.5跟0.25的狀況下雖然速度變快但精准度如上圖所示可以看出效果很差。<br><img src="/media/15172353341447.png" alt=""></p>
<h4 id="加速方法-2-利用較小的feature-map來做inference-Downsampling-Feature"><a href="#加速方法-2-利用較小的feature-map來做inference-Downsampling-Feature" class="headerlink" title="加速方法 2 : 利用較小的feature map來做inference(Downsampling Feature)"></a>加速方法 2 : 利用較小的feature map來做inference(Downsampling Feature)</h4><p>FCN Downsampling到32倍, Deep Lab到 8倍, 而下方是用作者之前的PSPNet50, 縮小到了1:8, 1:16, 1:32整理的Table, 但可以看到最快的速度也只有132ms, 不太能符合real-time的標準。<br><img src="/media/15172758974357.png" alt=""></p>
<h4 id="加速方法-3-減少模型複雜度-Model-Compression"><a href="#加速方法-3-減少模型複雜度-Model-Compression" class="headerlink" title="加速方法 3 : 減少模型複雜度(Model Compression)"></a>加速方法 3 : 減少模型複雜度(Model Compression)</h4><p>採用了其他篇paper(Pruning filters for efficient convnets)，作法就是減少Filter數量, 但一樣差強人意<br> <img src="/media/15172822508697.jpg" alt=""></p>
<h4 id="FCN-Fully-Convolutional-Networks-for-Fully-Convolutional-Networks"><a href="#FCN-Fully-Convolutional-Networks-for-Fully-Convolutional-Networks" class="headerlink" title="FCN:Fully Convolutional Networks for Fully Convolutional Networks"></a>FCN:Fully Convolutional Networks for Fully Convolutional Networks</h4><p>這裡額外多講一下FCN，算是CNN做semantic segmentation的始祖，本質上的區別大概就是…FCN是沒有全連結層的CNN，好處是可以接受任意大小輸入。<br><img src="/media/15172765679435.jpg" alt=""></p>
<p>CNN要如何轉FCN? 以此篇paper為例，input是一個224x224x3的圖，經過一系列Conv跟Downsampling之後是7x7x512。<br>AlexNet使用了兩個4096的全連接層，最後一個有1000個神經元的全連接層用於計算分類評分。我們可以將這3個全連接層轉化為Convolution層。</p>
<p>任一全連結層轉化為Conv的方式以以下為例：</p>
<h6 id="例如-K-4096-的全連接層，輸入是7x7x512，這個全連接層可以被等效地看做一個F-7-Padding-0-Stride-1-Filter-Number-4096-的Conv層。換句話說，就是將Filter-Size設置的和Input-Data-Size一致了。輸出將變成-1x1x4096，這個結果就和使用初始的那個全連接層一樣了。"><a href="#例如-K-4096-的全連接層，輸入是7x7x512，這個全連接層可以被等效地看做一個F-7-Padding-0-Stride-1-Filter-Number-4096-的Conv層。換句話說，就是將Filter-Size設置的和Input-Data-Size一致了。輸出將變成-1x1x4096，這個結果就和使用初始的那個全連接層一樣了。" class="headerlink" title="例如 K=4096 的全連接層，輸入是7x7x512，這個全連接層可以被等效地看做一個F=7,Padding=0,Stride=1,Filter Number=4096 的Conv層。換句話說，就是將Filter Size設置的和Input Data Size一致了。輸出將變成 1x1x4096，這個結果就和使用初始的那個全連接層一樣了。"></a>例如 K=4096 的全連接層，輸入是7x7x512，這個全連接層可以被等效地看做一個F=7,Padding=0,Stride=1,Filter Number=4096 的Conv層。換句話說，就是將Filter Size設置的和Input Data Size一致了。輸出將變成 1x1x4096，這個結果就和使用初始的那個全連接層一樣了。</h6><p>針對第一個連接區域是[7x7x512]的全連接層，令其Filter Size為F=7<strong>（Filter Size為7x7）</strong>，這樣輸出為[1x1x4096]。<br>針對第二個全連接層，令其Filter Size為F=1<strong>（Filter Size為1x1）</strong>，這樣輸出為[1x1x4096]。<br>對最後一個全連接層也做類似的，令其F=1<strong>（Filter Size為1x1）</strong>，最終輸出為[1x1x1000]</p>
<h5 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1:"></a>Step 1:</h5><p>下圖是是原始CNN結構，CNN中輸入的圖像大小是統一固定resize成227x227大小的圖像，第一層pooling後為55x55，第二層pooling後為27x27，第五層pooling後的圖像大小為13*13。<br><img src="/media/15172417899356.jpg" alt=""></p>
<h5 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2:"></a>Step 2:</h5><p>FCN輸入的圖像是假設是H*W，第一層pooling後變為原圖大小的1/4，第二層變為的1/8，第五層變為1/ 16，第八層變為1/32<br><img src="/media/15172417973947.jpg" alt=""></p>
<h5 id="Step-3"><a href="#Step-3" class="headerlink" title="Step 3:"></a>Step 3:</h5><p>Convolution本質上就是DownSampling（下採樣）。經過多次Convolution和pooling以後，得到的圖像越來越小，解析度越來越低。其中圖像到H/32∗W/32 的時候圖片是最小的一層時，所產生圖叫做heatmap，heatmap就是我們最重要的高維特徵圖，得到高維特徵的heatmap之後就是最重要的一步也是最後的一步，就是對此heatmap進行UpSampling(Deconvolution)，把圖像進行放大到原圖像的大小。</p>
<p><img src="/media/15172418178955.jpg" alt=""></p>
<h5 id="Step-4"><a href="#Step-4" class="headerlink" title="Step 4:"></a>Step 4:</h5><p>最後的輸出是1000張heatmap經過UpSampling變為原圖大小的圖片。<br><img src="/media/15172418074043.jpg" alt=""></p>
<h5 id="Upsampling"><a href="#Upsampling" class="headerlink" title="Upsampling"></a>Upsampling</h5><p><img src="/media/20161024115403020.gif" alt=""><br>其實這篇paper內雖然叫做Deconvolution，但之前CS231n課程內的大神也有說到，叫做Transposed Convolution比較適合。<br>舉個例子來說：</p>
<p>4x4的圖片輸入，Filter Size為3x3, 沒有Padding / Stride, 則輸出為2x2。</p>
<p>輸入矩陣可展開為16維向量，記作<em>x</em><br>輸出矩陣可展開為4維向量，記作<em>y</em><br>Convolution運算可表示為<em>y</em>=<em>Cx</em><br>C其實就是如下的稀疏陣，而Forwarding就改成了的矩陣運算<br><img src="/media/15172789125366.jpg" alt=""><br>BackPropagation的話，假若已經從更深的網路得到了</p>
<p><center><img src="/media/15172790446136.jpg" alt=""></center><br>那麼就可以導出以下公式:<br><img src="/media/15172790496567.jpg" alt=""><br>Deconvolution其實就是Forwarding時乘CT，而BackPropagation時乘(CT)T，即C。總結來說，Deconvolution等於Convolution在神經網絡結構的正向和反向傳播中的計算，做相反的計算。</p>
<h5 id="Skip-Architecture"><a href="#Skip-Architecture" class="headerlink" title="Skip Architecture"></a>Skip Architecture</h5><p>由於縮小32倍結果超糟糕，所以FCN在前面的Pooling Layer進行Upsampling，然後結合這些結果來優化輸出。<br><img src="/media/15172794424801.jpg" alt=""></p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>總結一下前面速度分析的結果，一系列的優化方法：</p>
<ul>
<li>Downsampling Input：降低輸入解析度能都大幅度的加速，但同時會讓預測非常模糊</li>
<li>Downsampling Feature：可以加速但同時會降低準確率</li>
<li>Model Compression：壓縮訓練好的模型，通過減輕模型達到加速效果，可惜實驗效果不佳</li>
</ul>
<p>針對以上的分析，發現，低解析度的圖片能夠有效降低運行時間，但是失去很多細節，而且邊界模糊；但是高解析度的計算時間難以忍受，ICNet總結了上述幾個問題，提出了一個綜合性的方法：使用低解析度加速捕捉語義，使用高解析度獲取細節，使用特徵融合(CFF)結合，同時使用guide label來監督，在限制的時間內獲得有效的結果。</p>
<p><img src="/media/15172827737568.png" alt=""></p>
<h4 id="Branch-Analysis"><a href="#Branch-Analysis" class="headerlink" title="Branch Analysis"></a>Branch Analysis</h4><p>圖中用了原尺寸,1/2,1/4當input，低解析度分枝超過50層Convolution，來提取更多的語義信息(inference 18 ms)，中解析度分枝有17層Convolution，但是由於權重共享，只有inference 6ms，而高解析度分枝是3 Convolution，有inference 9ms.</p>
<table>
<thead>
<tr>
<th style="text-align:center">分枝</th>
<th>過程</th>
<th>耗時</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">低解析</td>
<td>低解析是FCN-based PSPNet的架構，總和有超過50層的Convolution，在中解析度的1/16輸出的基礎上，再縮放到1/32.經過Convolution後，然後使用幾個dilated convolution擴展接受野但不縮小尺寸，最終以原圖的1/32大小輸出feature map。</td>
<td>雖然層數較多，但是解析度低，速度快，且與分枝二共享一部分權重，耗時為18 ms</td>
</tr>
<tr>
<td style="text-align:center">中解析</td>
<td>以原圖的1/2的解析度作為輸入，經過17層Convolution後以1/8縮放，得到原圖的1/16大小feature map，再將低解析度分枝的輸出feature map通過CFF(cascade feature fusion )單元相融合得到最終輸出。值得注意的是：低解析度和中解析度的捲積參數是共享的。</td>
<td>有17個Convolution層，與分枝一共享一部分權重，與分枝一一起一共耗時6ms</td>
</tr>
<tr>
<td style="text-align:center">高解析</td>
<td>原圖輸入，經過三層的Convolution(Stride=2,Size=3x3)得到原圖的1/8大小的feature map，再將中解析度處理後的輸出通過CFF單元融合</td>
<td>有3個卷積層，雖然解析度高，因為少，耗時為9ms</td>
</tr>
</tbody>
</table>
<p>對於每個分枝的輸出特徵，首先會上採樣2倍做輸出，在訓練的時候，會以Ground truth的1/16、1/8/、1/4來指導各個分枝的訓練，這樣的輔助訓練使得梯度優化更為平滑，便於訓練收斂，隨著每個分枝學習能力的增強，預測沒有被任何一個分枝主導。利用這樣的漸變的特徵融合和級聯引導結構可以產生合理的預測結果。</p>
<p>ICNet使用低解析度完成語義分割，使用高解析度幫助細化結果。在結構上，產生的feature大大減少，同時仍然保持必要的細節。</p>
<h4 id="Cascade-Label-Guidance"><a href="#Cascade-Label-Guidance" class="headerlink" title="Cascade Label Guidance"></a>Cascade Label Guidance</h4><h4 id="Branch-Output"><a href="#Branch-Output" class="headerlink" title="Branch Output"></a>Branch Output</h4><p>不同分枝的預測效果如下:<br><img src="/media/15172838466580.png" alt=""></p>
<p>可以看到第三個分枝輸出效果無疑是最好的。在測試時，只保留第三分枝的結果。</p>
<h2 id="Cascade-Feature-Fusion"><a href="#Cascade-Feature-Fusion" class="headerlink" title="Cascade Feature Fusion"></a>Cascade Feature Fusion</h2><p><img src="/media/15172845289475.jpg" alt=""><br>圖中的Loss是輔助Loss,F1是較低解析的分枝, F2是較高解析的分枝，</p>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>L=λ1L1+λ2L2+λ3L3<br>Loss是對應到每個downsampled score maps使用cross-entropy loss</p>
<p>依據CFF的設置，下分枝的lossL3的佔比λ3設置為1的話,則中分枝的lossL2的佔比λ2設置為0.4，上分枝的lossL1的佔比λ1設置為0.16</p>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><table>
<thead>
<tr>
<th style="text-align:center">項目</th>
<th style="text-align:center">設置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">平台</td>
<td style="text-align:center">Caffe，CUDA7.5 cudnnV5，TitanX一張</td>
</tr>
<tr>
<td style="text-align:center">測量時間</td>
<td style="text-align:center">Caffe Time 100次取平均</td>
</tr>
<tr>
<td style="text-align:center">Batch Size</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td style="text-align:center">學習速率</td>
<td style="text-align:center">Poly, Learning Rate 0.01, Momentum 0.9</td>
</tr>
<tr>
<td style="text-align:center">迭代次數</td>
<td style="text-align:center">30K</td>
</tr>
<tr>
<td style="text-align:center">權重衰減</td>
<td style="text-align:center">0.0001</td>
</tr>
<tr>
<td style="text-align:center">數據增強</td>
<td style="text-align:center">Random flip, 0.5 to 2 random scale</td>
</tr>
<tr>
<td style="text-align:center">資料集</td>
<td style="text-align:center">Cityscapes</td>
</tr>
</tbody>
</table>
<h4 id="model-Compression"><a href="#model-Compression" class="headerlink" title="model Compression"></a>model Compression</h4><p>以PSPNet50為例，直接壓縮結果如下表Baseline：</p>
<p><img src="/media/15173712115585.png" alt=""></p>
<p>mIoU降低了，但時間170ms達不到realtime。這表明只有模型壓縮是達不到有良好分割結果的實時性能。對比ICNet，有類似的分割結果，但速度提升了5倍多。</p>
<h4 id="Cascade-Structure-Experiment"><a href="#Cascade-Structure-Experiment" class="headerlink" title="Cascade Structure Experiment"></a>Cascade Structure Experiment</h4><p><img src="/media/15173713226717.png" alt=""><br>sub4代表只有低解析度輸入的結果，sub24代表前兩個分枝，sub124全部分枝。注意到全部分枝的速度很快，並且性能接近PSPNet了，且能保持30fps。而且Ram消耗也明顯減少了。</p>
<h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p><img src="/media/15173715003744.jpg" alt=""></p>
<h4 id="Cityscape-Comparison"><a href="#Cityscape-Comparison" class="headerlink" title="Cityscape Comparison"></a>Cityscape Comparison</h4><p><img src="/media/15173715775469.jpg" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/14/Distance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/14/Distance/" itemprop="url">
                  機器學習中的相似性度量
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-14T02:12:19+08:00">
                2018-01-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Euclidean-Distance-歐幾里和距離"><a href="#Euclidean-Distance-歐幾里和距離" class="headerlink" title="Euclidean Distance(歐幾里和距離)"></a>Euclidean Distance(歐幾里和距離)</h2><p>二維與三維中就是兩點之間的距離。</p>
<p><img src="/media/15158672262601.jpg" alt=""></p>
<p>上圖中的綠線為歐氏距離，又稱歐幾里和距離(Euclidean Distance)，其餘的藍色與黃色還有紅色皆為曼哈頓距離。</p>
<h2 id="Manhattan-distance-曼哈頓距離"><a href="#Manhattan-distance-曼哈頓距離" class="headerlink" title="Manhattan distance(曼哈頓距離)"></a>Manhattan distance(曼哈頓距離)</h2><p>平面上，坐標（x1, y1）的點P1與坐標（x2, y2）的點P2的曼哈頓距離為：<br><img src="/media/15158673215658.jpg" alt=""></p>
<p>L1-距離</p>
<h2 id="Mahalanobis-distance-馬氏距離"><a href="#Mahalanobis-distance-馬氏距離" class="headerlink" title="Mahalanobis distance(馬氏距離)"></a>Mahalanobis distance(馬氏距離)</h2><p><a href="https://zh.wikipedia.org/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5" target="_blank" rel="external">Covariance Matrix</a></p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Mahalanobis distance can be defined <span class="keyword">as</span> <span class="keyword">a</span> dissimilarity measure between <span class="literal">two</span> <span class="built_in">random</span> vectors x <span class="keyword">and</span> y <span class="keyword">of</span> <span class="keyword">the</span> same distribution <span class="keyword">with</span> <span class="keyword">the</span> covariance matrix S:</div></pre></td></tr></table></figure>
<p><img src="/media/15158695072163.jpg" alt=""><br><img src="/media/15158699156018.jpg" alt=""></p>
<h2 id="Chebyshev-distance-切比雪夫距離"><a href="#Chebyshev-distance-切比雪夫距離" class="headerlink" title="Chebyshev distance(切比雪夫距離)"></a>Chebyshev distance(切比雪夫距離)</h2><h2 id="Minkowski-distance-明可夫斯基距離"><a href="#Minkowski-distance-明可夫斯基距離" class="headerlink" title="Minkowski distance (明可夫斯基距離)"></a>Minkowski distance (明可夫斯基距離)</h2><p><a href="http://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html" target="_blank" rel="external">http://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/14/Deep-Sort/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/14/Deep-Sort/" itemprop="url">
                  Deep Sort: Simple Online and Realtime Tracking with a Deep Association Metric
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-14T01:38:43+08:00">
                2018-01-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MOT/" itemprop="url" rel="index">
                    <span itemprop="name">MOT</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此篇文章是基於SORT的改進<br>具體來說就是一句話</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">We adopt <span class="keyword">a</span> conventional single hypothesis tracking methodology <span class="keyword">with</span> recursive kalman filtering <span class="keyword">and</span> frame-<span class="keyword">by</span>-frame data association.</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/10/Multiple-Object-Tracking-Summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/10/Multiple-Object-Tracking-Summary/" itemprop="url">
                  Multiple Object Tracking Summary
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-10T20:03:49+08:00">
                2018-01-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MOT/" itemprop="url" rel="index">
                    <span itemprop="name">MOT</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://perception.yale.edu/Brian/refGuides/MOT.html" target="_blank" rel="external">http://perception.yale.edu/Brian/refGuides/MOT.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/09/Deep-Learning-Recommended-Papers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/09/Deep-Learning-Recommended-Papers/" itemprop="url">
                  Deep Learning and Computer Vision Recommended Paper
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-09T21:50:49+08:00">
                2018-01-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><h4 id="Must-Read-LeNet-AlexNet-VGG-16-GoogleNet-ResNet"><a href="#Must-Read-LeNet-AlexNet-VGG-16-GoogleNet-ResNet" class="headerlink" title="Must Read : LeNet, AlexNet, VGG-16, GoogleNet, ResNet"></a>Must Read : LeNet, AlexNet, VGG-16, GoogleNet, ResNet</h4><table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Authors</th>
<th style="text-align:center">Pub.</th>
<th style="text-align:center">Links</th>
<th style="text-align:center">Figure</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">LeNet-5, convolutional neural networks</td>
<td style="text-align:center">Y. LeCun</td>
<td style="text-align:center">??? 199X</td>
<td style="text-align:center"><a href="http://yann.lecun.com/exdb/lenet/" target="_blank" rel="external">Web</a></td>
<td style="text-align:center"><img src="/media/data/LeNet.png" alt="LeNet"></td>
</tr>
<tr>
<td style="text-align:center">ImageNet Classification with Deep Convolutional Neural Networks</td>
<td style="text-align:center">Alex Krizhevsky,Ilya Sutskever,Geoffrey E. Hinton</td>
<td style="text-align:center">NIPS 2014</td>
<td style="text-align:center"><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/AlexNet.jpg" alt="AlexNet"></td>
</tr>
<tr>
<td style="text-align:center">Very Deep Convolutional Networks for Large-Scale Image Recognition</td>
<td style="text-align:center">Karen Simonyan, Andrew Zisserman</td>
<td style="text-align:center">ICLR 2014</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/VGG16.png" alt="VGG16"></td>
</tr>
<tr>
<td style="text-align:center">Going Deeper with Convolutions</td>
<td style="text-align:center">Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed</td>
<td style="text-align:center">CVPR 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/GoogLeNet.png" alt="GoogLeNet"></td>
</tr>
<tr>
<td style="text-align:center">Deep Residual Learning for Image Recognition</td>
<td style="text-align:center">Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun</td>
<td style="text-align:center">CVPR 2016 <em><code>best</code></em></td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">paper</a> <a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/ResNet.png" alt="ResNet"></td>
</tr>
<tr>
<td style="text-align:center">Residual Attention Network for Image Classification</td>
<td style="text-align:center">Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang, Xiaogang Wang, Xiaoou Tang</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1704.06904" target="_blank" rel="external">paper</a> <a href="https://github.com/buptwangfei/residual-attention-network" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/Res-Attention-Network.png" alt="Res-Attention-Network"></td>
</tr>
<tr>
<td style="text-align:center">Aggregated Residual Transformations for Deep Neural Networks</td>
<td style="text-align:center">Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.05431" target="_blank" rel="external">paper</a> <a href="https://github.com/facebookresearch/ResNeXt" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/ResNeXt.png" alt="ResNeXt"></td>
</tr>
<tr>
<td style="text-align:center">Densely Connected Convolutional Networks</td>
<td style="text-align:center">Gao Huang, Zhuang Liu, Kilian Q. Weinberger</td>
<td style="text-align:center">CVPR 2017 <em><code>best</code></em></td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="external">paper</a> <a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/DenseNet.png" alt="DenseNet"></td>
</tr>
<tr>
<td style="text-align:center">Deep Pyramidal Residual Networks</td>
<td style="text-align:center">Dongyoon Han, Jiwhan Kim, Junmo Kim</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1610.02915.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/jhkim89/PyramidNet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/PyramidNet.png" alt="PyramidNet"></td>
</tr>
</tbody>
</table>
<h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><h4 id="Must-Read-R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD"><a href="#Must-Read-R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD" class="headerlink" title="Must Read : R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD"></a>Must Read : R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD</h4><table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Authors</th>
<th style="text-align:center">Pub.</th>
<th style="text-align:center">Links</th>
<th style="text-align:center">Figure</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Rich feature hierarchies for accurate object detection and semantic segmentation</td>
<td style="text-align:center">Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik</td>
<td style="text-align:center">CVPR 2014</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/rbgirshick/rcnn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/R-CNN.png" alt="R-CNN"></td>
</tr>
<tr>
<td style="text-align:center">Fast R-CNN</td>
<td style="text-align:center">Ross Girshick</td>
<td style="text-align:center">ICCV 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/Fast-R-CNN.png" alt="Fast-R-CNN"></td>
</tr>
<tr>
<td style="text-align:center">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</td>
<td style="text-align:center">Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>
<td style="text-align:center">TPAMI 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/SPP-Net.png" alt="SPP Net"></td>
</tr>
<tr>
<td style="text-align:center">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</td>
<td style="text-align:center">Shaoqing Ren, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Ross Girshick, Jian Sun</td>
<td style="text-align:center">NIPS 2015</td>
<td style="text-align:center"><a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external"><code>matlab</code></a> <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external"><code>python</code></a> <a href="https://github.com/longcw/faster_rcnn_pytorch" target="_blank" rel="external"><code>pytorch</code></a></td>
<td style="text-align:center"><img src="/media/data/Faster-R-CNN.png" alt="Faster-R-CNN"></td>
</tr>
<tr>
<td style="text-align:center">You Only Look Once: Unified, Real-Time Object Detection</td>
<td style="text-align:center">Joseph Redmon,Santosh Divvala,Ross Girshick, Ali Farhadi</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://arxiv.org/pdf/1506.02640.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/YOLO.jpg" alt="YOLO"></td>
</tr>
<tr>
<td style="text-align:center">SSD: Single Shot MultiBox Detector</td>
<td style="text-align:center">Wei Liu1, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://arxiv.org/pdf/1512.02325.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/SSD.png" alt="SSD"></td>
</tr>
<tr>
<td style="text-align:center">Convolutional Feature Masking for Joint Object and Stuff Segmentation</td>
<td style="text-align:center">Jifeng Dai, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Jian Sun</td>
<td style="text-align:center">CVPR 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/CFM.png" alt="CFM"></td>
</tr>
<tr>
<td style="text-align:center">Instance-aware Semantic Segmentation via Multi-task Network Cascades</td>
<td style="text-align:center">Jifeng Dai, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Jian Sun</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Dai_Instance-Aware_Semantic_Segmentation_CVPR_2016_paper.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/daijifeng001/MNC" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/MNC.png" alt="MNC"></td>
</tr>
<tr>
<td style="text-align:center">R-FCN: Object Detection via Region-based Fully Convolutional Networks</td>
<td style="text-align:center">Jifeng Dai, Yi Li, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Jian Sun</td>
<td style="text-align:center">NIPS 2016</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1605.06409" target="_blank" rel="external">paper</a> <a href="https://github.com/daijifeng001/R-FCN" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/Region-FCN.png" alt="Region-FCN"></td>
</tr>
<tr>
<td style="text-align:center">Feature Pyramid Networks for Object Detection</td>
<td style="text-align:center">Tsung-Yi Lin, Piotr Dollár, Ross Girshick, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Bharath Hariharan, and Serge Belongie</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1612.03144.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/FPN.png" alt="FPN"></td>
</tr>
<tr>
<td style="text-align:center">Mask R-CNN</td>
<td style="text-align:center">Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick</td>
<td style="text-align:center">ICCV 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/Mask-R-CNN.png" alt="Mask-R-CNN"></td>
</tr>
<tr>
<td style="text-align:center">A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</td>
<td style="text-align:center">Xiaolong Wang, Abhinav Shrivastava, Abhinav Gupta</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1704.03414" target="_blank" rel="external">paper</a>  <a href="https://github.com/xiaolonw/adversarial-frcnn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/A-Fast-R-CNN.png" alt="A-Fast-R-CNN"></td>
</tr>
<tr>
<td style="text-align:center">Multiple Instance Detection Network with Online Instance Classifier Refinement</td>
<td style="text-align:center">Peng Tang, Xinggang Wang, Xiang Bai, Wenyu Liu</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1704.00138" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/MIDN.png" alt="MIDN"></td>
</tr>
<tr>
<td style="text-align:center">R-FCN-3000 at 30fps: Decoupling Detection and Classification</td>
<td style="text-align:center">Bharat Singh, Hengdou Li, Abhishek Sharma and Larry S. Davis</td>
<td style="text-align:center">Tech Report</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1712.01802" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/R-FCN-3000.png" alt="R-FCN-3000"></td>
</tr>
</tbody>
</table>
<h2 id="Semantic-Segmentation-and-Scene-Parsing"><a href="#Semantic-Segmentation-and-Scene-Parsing" class="headerlink" title="Semantic Segmentation and Scene Parsing"></a>Semantic Segmentation and Scene Parsing</h2><h4 id="Must-Read-FCN-Learning-Deconvolution-Network-for-Semantic-Segmentation-U-Net"><a href="#Must-Read-FCN-Learning-Deconvolution-Network-for-Semantic-Segmentation-U-Net" class="headerlink" title="Must Read : FCN, Learning Deconvolution Network for Semantic Segmentation, U-Net"></a>Must Read : FCN, Learning Deconvolution Network for Semantic Segmentation, U-Net</h4><table>
<thead>
<tr>
<th>Title</th>
<th style="text-align:center">Authors</th>
<th style="text-align:center">Pub.</th>
<th style="text-align:center">Links</th>
<th style="text-align:center">Figure</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fully Convolutional Networks for Semantic Segmentation</td>
<td style="text-align:center">Jonathan Long, Evan Shelhamer, Trevor Darrell</td>
<td style="text-align:center">CVPR 2015</td>
<td style="text-align:center"><a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/FCN.png" alt="FCN"></td>
</tr>
<tr>
<td>Learning to Segment Object Candidates</td>
<td style="text-align:center">Pedro O. Pinheiro, Ronan Collobert, Piotr Dollar</td>
<td style="text-align:center">NIPS 2015</td>
<td style="text-align:center"><a href="http://papers.nips.cc/paper/5852-learning-to-segment-object-candidates.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/LSOC.png" alt="LSOC"></td>
</tr>
<tr>
<td>Learning to Refine Object Segments</td>
<td style="text-align:center">Pedro O. Pinheiro , Tsung-Yi Lin , Ronan Collobert, Piotr Doll ́ar</td>
<td style="text-align:center">arXiv 1603.08695</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1603.08695.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/LROS.png" alt="LROS"></td>
</tr>
<tr>
<td>Conditional Random Fields as Recurrent Neural Networks</td>
<td style="text-align:center">Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, ZhiZhong Su, Dalong Du, Chang Huang, and Philip H. S. Torr</td>
<td style="text-align:center">ICCV 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zheng_Conditional_Random_Fields_ICCV_2015_paper.html" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/CRFRNN.png" alt="CRFRNN"></td>
</tr>
<tr>
<td>Learning Deconvolution Network for Semantic Segmentation</td>
<td style="text-align:center">Heonwoo Noh, Seunghoon Hong, Bohyung Han</td>
<td style="text-align:center">ICCV 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.html" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/LDN.png" alt="LDN"></td>
</tr>
<tr>
<td>U-Net: Convolutional Networks for Biomedical Image Segmentation</td>
<td style="text-align:center">Olaf Ronneberger, Philipp Fischer, Thomas Brox</td>
<td style="text-align:center">MICCAI 2015</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/U-Net.png" alt="U-Net"></td>
</tr>
<tr>
<td>Instance-sensitive Fully Convolutional Networks</td>
<td style="text-align:center">Jifeng Dai, Kaiming He, Yi Li, Shaoqing Ren, Jian Sun</td>
<td style="text-align:center">ECCV 2016</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1603.08678" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/ISFCN.png" alt="ISFCN"></td>
</tr>
<tr>
<td>Laplacian Pyramid Reconstruction and Refinement for Semantic Segmentation</td>
<td style="text-align:center">Golnaz Ghiasi, Charless C. Fowlkes</td>
<td style="text-align:center">ECCV 2016</td>
<td style="text-align:center"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_32" target="_blank" rel="external">paper</a>  <a href="https://github.com/golnazghiasi/LRR" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/LPRR.png" alt="LPRR"></td>
</tr>
<tr>
<td>Attention to Scale: Scale-aware Semantic Image Segmentation</td>
<td style="text-align:center">Liang-Chieh Chen, Yi Yang, Jiang Wang, Wei Xu</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Chen_Attention_to_Scale_CVPR_2016_paper.html" target="_blank" rel="external">paper</a> <a href="http://liangchiehchen.com/projects/DeepLab.html" target="_blank" rel="external"><code>DeepLab</code></a></td>
<td style="text-align:center"><img src="/media/data/Attention-to-scale.png" alt="Attention-to-scale"></td>
</tr>
<tr>
<td>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</td>
<td style="text-align:center">Guosheng Lin, Anton Milan, Chunhua Shen, Ian Reid</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">paper</a>  <a href="https://github.com/guosheng/refinenet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/RefineNet.png" alt="RefineNet"></td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>Pyramid Scene Parsing Network</td>
<td style="text-align:center">Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="external">paper</a>  <a href="https://github.com/hszhao/PSPNet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/PSPNet.png" alt="PSPNet"></td>
</tr>
<tr>
<td>ICNet for Real-Time Semantic Segmentation on High-Resolution Images</td>
<td style="text-align:center">Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, Jiaya Jia</td>
<td style="text-align:center">Tech Report</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/ICNet.png" alt="ICNet"></td>
</tr>
<tr>
<td>Dilated Residual Networks</td>
<td style="text-align:center">Fisher Yu, Vladlen Koltun, Thomas Funkhouser</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1705.09914" target="_blank" rel="external">paper</a> <a href="https://github.com/fyu/drn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/DRN.png" alt="DRN"></td>
</tr>
<tr>
<td>Fully Convolutional Instance-aware Semantic Segmentation</td>
<td style="text-align:center">Yi Li, Haozhi Qi, Jifeng Dai, Xiangyang Ji, Yichen Wei</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.07709" target="_blank" rel="external">paper</a> <a href="https://github.com/msracver/FCIS" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/FCIS.png" alt="FCIS"></td>
</tr>
<tr>
<td>Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes</td>
<td style="text-align:center">Tobias Pohlen, Alexander Hermans, Markus Mathias, Bastian Leibe</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.08323" target="_blank" rel="external">paper</a> <a href="https://github.com/TobyPDE/FRRN" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><img src="/media/data/FRRN.png" alt="FRRN"></td>
</tr>
<tr>
<td>Object Region Mining with Adversarial Erasing: A Simple Classification toSemantic Segmentation Approach</td>
<td style="text-align:center">Yunchao Wei, Jiashi Feng, Xiaodan Liang, Ming-Ming Cheng, Yao Zhao, Shuicheng Yan</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1703.08448" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/A-Erasing.png" alt="A-Erasing"></td>
</tr>
<tr>
<td>Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade</td>
<td style="text-align:center">Xiaoxiao Li, Ziwei Liu, Ping Luo, Chen Change Loy, Xiaoou Tang</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1704.01344.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/Not-All-Pixels-Are-Equal.png" alt="Not-All-Pixels-Are-Equal"></td>
</tr>
<tr>
<td>Semantic Segmentation with Reverse Attention</td>
<td style="text-align:center">Qin Huang, Chunyang Xia, Wuchi Hao, Siyang Li, Ye Wang, Yuhang Song and C.-C. Jay Kuo</td>
<td style="text-align:center">BMVC 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1707.06426" target="_blank" rel="external">paper</a> <a href="https://drive.google.com/drive/folders/0By2w_AaM8Rzbllnc3JCQjhHYnM?usp=sharing" target="_blank" rel="external"><code>code</code></a></td>
<td style="text-align:center"><img src="/media/data/Rev-Attention.png" alt="Rev-Attention"></td>
</tr>
<tr>
<td>Predicting Deeper into the Future of Semantic Segmentation</td>
<td style="text-align:center">Pauline Luc, Natalia Neverova, Camille Couprie, Jakob Verbeek and Yann LeCun</td>
<td style="text-align:center">ICCV 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1703.07684" target="_blank" rel="external">paper</a> <a href="https://thoth.inrialpes.fr/people/pluc/iccv2017" target="_blank" rel="external"><code>project page</code></a></td>
<td style="text-align:center"><img src="/media/data/Deeper-into-Future.png" alt="Deeper-into-Future"></td>
</tr>
<tr>
<td>Learning to Segment Every Thing</td>
<td style="text-align:center">Ronghang Hu, Piotr Dollar, Kaiming He, Trevor Darrell, Ross Girshick</td>
<td style="text-align:center">Tech Report</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1711.10370" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><img src="/media/data/Seg-Everything.png" alt="Seg-Everything"></td>
</tr>
</tbody>
</table>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><ul>
<li>Dropout- A Simple Way to Prevent Neural Networks from Overfitting</li>
<li>Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift</li>
</ul>
<h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><ul>
<li>Generating Sequences With Recurrent Neural Networks</li>
<li>Word embedding</li>
<li>Distributed Representations of Words and Phrases and their Compositionality</li>
</ul>
<h2 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h2><p>Show and Tell: A Neural Image Caption Generator<br>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2018/01/02/person_re-ID_summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/02/person_re-ID_summary/" itemprop="url">
                  Person re-ID Summary
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-02T21:50:49+08:00">
                2018-01-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Re-ID/" itemprop="url" rel="index">
                    <span itemprop="name">Re-ID</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/media/15149820234945.jpg" alt=""></p>
<h2 id="目標"><a href="#目標" class="headerlink" title="目標"></a>目標</h2><h2 id="難度"><a href="#難度" class="headerlink" title="難度"></a>難度</h2><ol>
<li>目標遮擋（Occlusion）導致部分特徵丟失</li>
<li>不同的 View，Illumination 導致同一目標的特徵差異</li>
<li>不同目標衣服顏色近似、特徵近似導致區分度下降</li>
</ol>
<h2 id="解決方案"><a href="#解決方案" class="headerlink" title="解決方案"></a>解決方案</h2><h3 id="1-Representation-learning-ReID"><a href="#1-Representation-learning-ReID" class="headerlink" title="1. Representation learning + ReID"></a>1. Representation learning + ReID</h3><p>看做分類(Classification/Identification)問題或者驗證(Verification)問題：<br>(1) 分類問題是指利用行人的ID或者屬性等作為訓練標籤來訓練模型；<br>(2) 驗證問題是指輸入一對（兩張）行人圖片，讓網絡來學習這兩張圖片是否屬於同一個行人。</p>
<p>Classification/Identification loss和verification loss</p>
<p><img src="/media/15150472221676.jpg" alt=""></p>
<p>額外改進方向[2]是在加上許多行人的label，像是性別、頭髮以及服裝等等。<br><img src="/media/15150474384428.jpg" alt=""></p>
<h3 id="2-Metric-learning-ReID"><a href="#2-Metric-learning-ReID" class="headerlink" title="2. Metric learning + ReID"></a>2. Metric learning + ReID</h3><p>常用於圖像檢索的方法，通過網絡學習出兩張圖片的相似度。<br>(Contrastive loss)[5]、三元組損失(Triplet loss)、 四元組損失(Quadruplet loss)、難樣本採樣三元組損失(Triplet hard loss with batch hard mining, TriHard loss)、邊界挖掘損失(Margin sample mining loss, MSML</p>
<p>Contrastive loss 基本上就是Siamese CNN<br><img src="/media/15150477657739.jpg" alt=""></p>
<p>訓練時是三個正樣本一個副樣本，test時未知<br><img src="/media/15150479915859.jpg" alt=""><br><img src="/media/15150480384222.jpg" alt=""></p>
<h3 id="3-Local-Feature-ReID"><a href="#3-Local-Feature-ReID" class="headerlink" title="3. Local Feature + ReID"></a>3. Local Feature + ReID</h3><p>論文[3]用local feature而不用global feature，切割好以後送到LSTM去學<br><img src="/media/15150481401848.jpg" alt=""></p>
<p>但論文[3]會有對齊問題，所以論文[4]用pose跟skeleton來做姿勢預測，再通過仿射變換對齊</p>
<p><img src="/media/15150485085441.jpg" alt=""></p>
<p>論文[5]直接拿關節點切出ROI，14個人體關節點，得到7個ROI區域，(頭、上身、下身和四肢)<br><img src="/media/15150485782017.jpg" alt=""></p>
<h3 id="4-Video-Sequence-ReID"><a href="#4-Video-Sequence-ReID" class="headerlink" title="4. Video Sequence + ReID"></a>4. Video Sequence + ReID</h3><p>這方向不熟 貼兩張圖參考參考而已<br><img src="/media/15150487793131.jpg" alt=""><br><img src="/media/15150488009610.jpg" alt=""></p>
<h3 id="5-GAN-ReID"><a href="#5-GAN-ReID" class="headerlink" title="5. GAN + ReID"></a>5. GAN + ReID</h3><p>ReID數據集目前最大的也只有幾千個ID，跟萬張圖片而已，CNN based還容易overfitting<br>GAN主要是用在遷移學習跟基於條件的生成</p>
<p>第一篇就是ICCV2017的論文[5]以及後來同作者改進的論文[6]，是可以避免overfitting但生成效果就很慘<br><img src="/media/15150491105798.jpg" alt=""></p>
<p>為了處理不同數據集，甚至是不同camera所造成bias的問題，論文[7]是利用cycleGAN based的設計，利用遷移學習來處理兩個數同數據集的問題，先切割分前景跟背景，在轉換過去。<br>D有兩個loss(還是有兩個D不確定，paper內沒架構圖)一個是前景的絕對誤差loss，一個是正常的判別器loss。判別器loss是用來判斷生成的圖屬於哪個domain，前景的loss是為了保證行人前景儘可能逼真不變。mask用PSPnet來找的。</p>
<p><img src="/media/15150492644360.jpg" alt=""></p>
<p>Pose Normalization[8]<br><img src="/media/15150490021821.jpg" alt=""><br><img src="/media/15150490274695.jpg" alt=""><br><img src="/media/15150495642066.jpg" alt=""></p>
<h2 id="資料種類"><a href="#資料種類" class="headerlink" title="資料種類"></a>資料種類</h2><ul>
<li>Video-based</li>
<li>Image-based</li>
<li>Long-term activity</li>
<li>Individual action </li>
</ul>
<h2 id="資料庫"><a href="#資料庫" class="headerlink" title="資料庫"></a>資料庫</h2><p><a href="http://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html" target="_blank" rel="external">Robust Systems Lab</a></p>
<h2 id="程式碼"><a href="#程式碼" class="headerlink" title="程式碼"></a>程式碼</h2><p><a href="https://zhuanlan.zhihu.com/p/32585203" target="_blank" rel="external">简单行人重识别代码到88%准确率</a><br><a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="external">https://github.com/layumi/Person_reID_baseline_pytorch</a></p>
<ul>
<li><h3 id="ICCV-2017"><a href="#ICCV-2017" class="headerlink" title="ICCV 2017"></a>ICCV 2017</h3><ul>
<li><a href="https://github.com/KovenYu/CAMEL" target="_blank" rel="external">Cross-view Asymmetric Metric Learning for Unsupervised Re-id </a></li>
<li><a href="https://github.com/zlmzju/part_reid" target="_blank" rel="external">Deeply-Learned Part-Aligned Representations for Person Re-Identification </a></li>
<li><a href="https://github.com/VisualComputingInstitute/triplet-reid" target="_blank" rel="external">In Defense of the Triplet Loss for Person Re-Identification </a></li>
<li><a href="https://github.com/shuangjiexu/Spatial-Temporal-Pooling-Networks-ReID" target="_blank" rel="external">Jointly Attentive Spatial-Temporal Pooling Networks for Video-based Person Re-Identification</a></li>
<li><a href="http://github.com/syfafterzy/SVDNet-for-Pedestrian-Retrieval" target="_blank" rel="external">SVDNet for Pedestrian Retrieval</a></li>
<li><a href="http://github.com/layumi/Person-reID_GAN" target="_blank" rel="external">Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro</a></li>
</ul>
</li>
</ul>
<ul>
<li><h3 id="CVPR-2017"><a href="#CVPR-2017" class="headerlink" title="CVPR 2017"></a>CVPR 2017</h3><ul>
<li><a href="http://github.com/yokattame/SpindleNet" target="_blank" rel="external">Spindle Net: Person Re-Identification With Human Body Region Guided Feature Decomposition and Fusion</a></li>
<li><a href="http://github.com/liangzheng06/PRW-baseline" target="_blank" rel="external">Person Re-Identification in the Wild</a> </li>
<li><a href="http://github.com/ShuangLI59/person_search" target="_blank" rel="external">Joint Detection and Identification Feature Learning for Person Search</a></li>
<li><a href="http//github.com/sciencefans/Quality-Aware-Network">Quality Aware Network for Set to Set Recognition</a></li>
</ul>
</li>
</ul>
<h2 id="Paper-List"><a href="#Paper-List" class="headerlink" title="Paper List"></a>Paper List</h2><pre><code>- Point to Set Similarity Based Deep Feature Learning for Person Re-Identification
- Fast Person Re-Identification via Cross-Camera Semantic Binary Transformation
- See the Forest for the Trees: Joint Spatial and Temporal Recurrent Neural Networks for Video-Based Person Re-Identification
- Learning Deep Context-Aware Features Over Body and Latent Parts for Person Re-Identification
- Consistent-Aware Deep Learning for Person Re-Identification in a Camera Network
- Re-Ranking Person Re-Identification With k-Reciprocal Encoding
- Multiple People Tracking by Lifted Multicut and Person Re-Identification
</code></pre><p>[1] Mengyue Geng, Yaowei Wang, Tao Xiang, Yonghong Tian. Deep transfer learning for person reidentification[J]. arXiv preprint arXiv:1611.05244, 2016.</p>
<p>[2] Yutian Lin, Liang Zheng, Zhedong Zheng, YuWu, Yi Yang. Improving person re-identification by attribute and identity learning[J]. arXiv preprint arXiv:1703.07220, 2017.</p>
<p>[3] Rahul Rama Varior, Bing Shuai, Jiwen Lu, Dong Xu, Gang Wang. A siamese long short-term memory architecture for human re-identification[C]//European Conference on Computer Vision. Springer, 2016:135–153.</p>
<p>[4]Liang Zheng, Yujia Huang, Huchuan Lu, Yi Yang. Pose invariant embedding for deep person reidentification[J]. arXiv preprint arXiv:1701.07732, 2017.</p>
<p>[5]  Haiyu Zhao, Maoqing Tian, Shuyang Sun, Jing Shao, Junjie Yan, Shuai Yi, Xiaogang Wang, Xiaoou Tang. Spindle net: Person re-identification with human body region guided feature decomposition and fusion[C]. CVPR, 2017.</p>
<p>[6] Zhong Z, Zheng L, Zheng Z, et al. Camera Style Adaptation for Person Re-identification[J]. arXiv preprint arXiv:1711.10295, 2017.</p>
<p>[7] Wei L, Zhang S, Gao W, et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification[J]. arXiv preprint arXiv:1711.08565, 2017.</p>
<p>[8] Qian X, Fu Y, Wang W, et al. Pose-Normalized Image Generation for Person Re-identification[J]. arXiv preprint arXiv:1712.02225, 2017.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2017/12/24/PYTHON中如何使用-ARGS和-KWARGS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/24/PYTHON中如何使用-ARGS和-KWARGS/" itemprop="url">
                  PYTHON中如何使用*ARGS和**KWARGS
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-24T18:48:14+08:00">
                2017-12-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Code/" itemprop="url" rel="index">
                    <span itemprop="name">Code</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>範例與翻譯理解自<a href="http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/" target="_blank" rel="external">連結</a>與<a href="http://appsgaga.com/python%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-init%E6%96%B9%E6%B3%95%E4%B8%AD%EF%BC%8Cargs-kwargs%E9%80%99%E5%85%A9%E5%80%8B%E5%8F%83%E6%95%B8%E6%98%AF%E4%BB%80%E9%BA%BC%EF%BC%9F/" target="_blank" rel="external">連結</a></p>
<h2 id="args跟-kwargs是類似的東西，是可有可無的參數。-一顆星的-args是tuple，可以接受很多的值。兩顆星的-kwargs一樣是可以接受很多值，但是是接受dictionary。"><a href="#args跟-kwargs是類似的東西，是可有可無的參數。-一顆星的-args是tuple，可以接受很多的值。兩顆星的-kwargs一樣是可以接受很多值，但是是接受dictionary。" class="headerlink" title="*args跟 **kwargs是類似的東西，是可有可無的參數。 一顆星的*args是tuple，可以接受很多的值。兩顆星的**kwargs一樣是可以接受很多值，但是是接受dictionary。"></a>*args跟 **kwargs是類似的東西，是可有可無的參數。 一顆星的*args是tuple，可以接受很多的值。兩顆星的**kwargs一樣是可以接受很多值，但是是接受dictionary。</h2><p>###一顆星用法</p>
<p>範例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_var_args</span><span class="params">(farg, *args)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"formal arg:"</span>, farg</div><div class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> args:</div><div class="line">        <span class="keyword">print</span> <span class="string">"another arg:"</span>, arg</div><div class="line">        </div><div class="line">test_var_args(<span class="number">1</span>, <span class="string">"two"</span>, <span class="number">3</span>)</div></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">formal arg: <span class="number">1</span></div><div class="line">another arg: two</div><div class="line">another arg: <span class="number">3</span></div></pre></td></tr></table></figure>
<p>###兩顆星用法</p>
<p>範例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_var_kwargs</span><span class="params">(farg, **kwargs)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"formal arg:"</span>, farg</div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> kwargs:</div><div class="line">        <span class="keyword">print</span> <span class="string">"another keyword arg: %s: %s"</span> % (key, kwargs[key])</div><div class="line"></div><div class="line">test_var_kwargs(farg=<span class="number">1</span>, myarg2=<span class="string">"two"</span>, myarg3=<span class="number">3</span>)</div></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">formal arg: <span class="number">1</span></div><div class="line">another keyword arg: myarg2: two</div><div class="line">another keyword arg: myarg3: <span class="number">3</span></div></pre></td></tr></table></figure>
<p><img src="/media/15141999823321.png" alt=""></p>
<h3 id="順序問題"><a href="#順序問題" class="headerlink" title="順序問題"></a>順序問題</h3><p>如果function定義時如上圖先放了tuple才是dictionary，呼叫時參數先放dictionary再放tuple會跳error。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2017/12/13/python-note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/13/python-note/" itemprop="url">
                  Python 筆記
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-13T15:35:34+08:00">
                2017-12-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Different in Py2 and Py3</p>
<p>Pickle module</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">if</span> sys.version_info[<span class="number">0</span>]&lt;<span class="number">3</span>:</div><div class="line">    <span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle</div><div class="line"><span class="keyword">else</span></div><div class="line">    <span class="keyword">import</span> _pickle <span class="keyword">as</span> pickle</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://world4jason.github.io/2017/12/01/zi2zi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason Yeh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="world4jason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/01/zi2zi/" itemprop="url">
                  zi2zi: Master Chinese Calligraphy with Conditional Adversarial Networks
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-01T03:36:19+08:00">
                2017-12-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GAN/" itemprop="url" rel="index">
                    <span itemprop="name">GAN</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/media/15128482902404.png" alt=""><br>Generated samples. Related code can be found <a href="https://github.com/kaonashi-tyc/zi2zi" target="_blank" rel="external">here</a></p>
<h2 id="目標"><a href="#目標" class="headerlink" title="目標"></a>目標</h2><p>字體風格轉換<br><img src="/media/15128485151045.png" alt=""></p>
<h2 id="動機"><a href="#動機" class="headerlink" title="動機"></a>動機</h2><p>直接用CNN進行風格轉換會有下列問題</p>
<ol>
<li>生成常常是模糊的</li>
<li>多數生成結果是失敗的</li>
<li>只能做一對一生成</li>
</ol>
<p><img src="/media/15128485338820.png" alt=""></p>
<p>結論：用GAN試試看</p>
<h2 id="用GAN秒殺一切！"><a href="#用GAN秒殺一切！" class="headerlink" title="用GAN秒殺一切！"></a>用GAN秒殺一切！</h2><p>這篇借鑒了三篇paper內容</p>
<p><a href="https://arxiv.org/abs/1611.07004" target="_blank" rel="external">Image-to-Image Translation with Conditional Adversarial Networks</a><br><a href="https://arxiv.org/abs/1610.09585" target="_blank" rel="external">Conditional Image Synthesis With Auxiliary Classifier GANs</a><br><a href="https://arxiv.org/abs/1611.02200" target="_blank" rel="external">Unsupervised Cross-Domain Image Generation</a></p>
<p>主要是由pix2pix這篇修改而來的<br><img src="/media/15128487302209.png" alt=""></p>
<p>其中Encoder跟Decoder還有Discriminator是直接用pix2pix的, 尤其是裡面的Unet模型</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Jason Yeh" />
          <p class="site-author-name" itemprop="name">Jason Yeh</p>
           
              <p class="site-description motion-element" itemprop="description">菜鳥搬磚日常</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">Artikel</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">Kategorien</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jason Yeh</span>
</div>


<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  













  





  

  

  

  

</body>
</html>
