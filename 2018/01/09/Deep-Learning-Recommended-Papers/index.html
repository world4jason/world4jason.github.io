<!DOCTYPE html>
<html lang="zh-TW">







<head>
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//pic.zhih.me">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">
	<link rel="preload" href="https://pic.zhih.me/blog/header.jpg" as="image">

	<title>Deep Learning and Computer Vision Recommended Paper | world4jason</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="Jason Yeh">
	<meta name="description" content="">

	
	<meta name="keywords" content="">
	

	
	<link rel="shortcut icon" href="https://i.loli.net/2017/11/26/5a19c0b50432e.png">
	<link rel="apple-touch-icon" href="https://i.loli.net/2017/11/26/5a19c0b50432e.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="world4jason">
	<meta property="og:type" content="article">
	<meta property="og:title" content="Deep Learning and Computer Vision Recommended Paper | world4jason">
	<meta property="og:description" content="">
	<meta property="og:url" content="https://world4jason.github.io/2018/01/09/Deep-Learning-Recommended-Papers/">

	
	<meta property="article:published_time" content="2018-01-09T21:01:00+08:00"> 
	<meta property="article:author" content="Jason Yeh">
	<meta property="article:published_first" content="world4jason, /2018/01/09/Deep-Learning-Recommended-Papers/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
<link rel="canonical" href="https://world4jason.github.io/2018/01/09/Deep-Learning-Recommended-Papers/"><!-- hexo-inject:begin --><!-- hexo-inject:end -->





</head>
<body class="post-template">
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                <a href="/" title="Home">HOME</a>
                
            </li>
            
            
            <li>
                <a href="/about" title="ABOUT">ABOUT</a>
            </li>
            
            <li>
                <a href="/archives" title="ARCHIVES">ARCHIVES</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    <a class="social-link" title="weibo" href="https://weibo.com/xzhih" target="_blank" rel="noopener">
        <svg viewbox="0 0 1141 1024" xmlns="http://www.w3.org/2000/svg"><path d="M916.48 518.144q27.648 21.504 38.912 51.712t9.216 62.976-14.336 65.536-31.744 59.392q-34.816 48.128-78.848 81.92t-91.136 56.32-94.72 35.328-89.6 18.944-75.264 7.68-51.712 1.536-49.152-2.56-68.096-10.24-78.336-21.504-79.872-36.352-74.24-55.296-59.904-78.848q-16.384-29.696-22.016-63.488t-5.632-86.016q0-22.528 7.68-51.2t27.136-63.488 53.248-75.776 86.016-90.112q51.2-48.128 105.984-85.504t117.248-57.856q28.672-10.24 63.488-11.264t57.344 11.264q10.24 11.264 19.456 23.04t12.288 29.184q3.072 14.336 0.512 27.648t-5.632 26.624-5.12 25.6 2.048 22.528q17.408 2.048 33.792-1.536t31.744-9.216 31.232-11.776 33.28-9.216q27.648-5.12 54.784-4.608t49.152 7.68 36.352 22.016 17.408 38.4q2.048 14.336-2.048 26.624t-8.704 23.04-7.168 22.016 1.536 23.552q3.072 7.168 14.848 13.312t27.136 12.288 32.256 13.312 29.184 16.384zM658.432 836.608q26.624-16.384 53.76-45.056t44.032-64 18.944-75.776-20.48-81.408q-19.456-33.792-47.616-57.344t-62.976-37.376-74.24-19.968-80.384-6.144q-78.848 0-139.776 16.384t-105.472 43.008-72.192 60.416-38.912 68.608q-11.264 33.792-6.656 67.072t20.992 62.976 42.496 53.248 57.856 37.888q58.368 25.6 119.296 32.256t116.224 0.512 100.864-21.504 74.24-33.792zM524.288 513.024q20.48 8.192 38.912 18.432t32.768 27.648q10.24 12.288 17.92 30.72t10.752 39.424 1.536 42.496-9.728 38.912q-8.192 18.432-19.968 37.376t-28.672 35.328-40.448 29.184-57.344 18.944q-61.44 11.264-117.76-11.264t-88.064-74.752q-12.288-39.936-13.312-70.656t16.384-66.56q13.312-27.648 40.448-51.712t62.464-38.912 75.264-17.408 78.848 12.8zM361.472 764.928q37.888 3.072 57.856-18.432t21.504-48.128-15.36-47.616-52.736-16.896q-27.648 3.072-43.008 23.552t-17.408 43.52 9.728 42.496 39.424 21.504zM780.288 6.144q74.752 0 139.776 19.968t113.664 57.856 76.288 92.16 27.648 122.88q0 33.792-16.384 50.688t-35.328 17.408-35.328-14.336-16.384-45.568q0-40.96-22.528-77.824t-59.392-64.512-84.48-43.52-96.768-15.872q-31.744 0-47.104-15.36t-14.336-34.304 18.944-34.304 51.712-15.36zM780.288 169.984q95.232 0 144.384 48.64t49.152 146.944q0 30.72-10.24 43.52t-22.528 11.264-22.528-14.848-10.24-35.84q0-60.416-34.816-96.256t-93.184-35.84q-19.456 0-28.672-10.752t-9.216-23.04 9.728-23.04 28.16-10.752z"/></svg>
    </a>
    
    
    <a class="social-link" title="github" href="https://github.com/xzhih" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2018-01-09T13:50:49.000Z">
                    2018-01-9
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/Deep-Learning/">Deep Learning</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">Deep Learning and Computer Vision Recommended Paper</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="lightgallery" class="markdown-body">
                    <h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><h4 id="Must-Read-LeNet-AlexNet-VGG-16-GoogleNet-ResNet"><a href="#Must-Read-LeNet-AlexNet-VGG-16-GoogleNet-ResNet" class="headerlink" title="Must Read : LeNet, AlexNet, VGG-16, GoogleNet, ResNet"></a>Must Read : LeNet, AlexNet, VGG-16, GoogleNet, ResNet</h4><table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Authors</th>
<th style="text-align:center">Pub.</th>
<th style="text-align:center">Links</th>
<th style="text-align:center">Figure</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">LeNet-5, convolutional neural networks</td>
<td style="text-align:center">Y. LeCun</td>
<td style="text-align:center">??? 199X</td>
<td style="text-align:center"><a href="http://yann.lecun.com/exdb/lenet/" target="_blank" rel="external">Web</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="LeNet" title="" class="post-img b-lazy" href="/media/data/LeNet.png" data-src="/media/data/LeNet.png">
                </div>
                <div class="image-caption">LeNet</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">ImageNet Classification with Deep Convolutional Neural Networks</td>
<td style="text-align:center">Alex Krizhevsky,Ilya Sutskever,Geoffrey E. Hinton</td>
<td style="text-align:center">NIPS 2014</td>
<td style="text-align:center"><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="AlexNet" title="" class="post-img b-lazy" href="/media/data/AlexNet.jpg" data-src="/media/data/AlexNet.jpg">
                </div>
                <div class="image-caption">AlexNet</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Very Deep Convolutional Networks for Large-Scale Image Recognition</td>
<td style="text-align:center">Karen Simonyan, Andrew Zisserman</td>
<td style="text-align:center">ICLR 2014</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="VGG16" title="" class="post-img b-lazy" href="/media/data/VGG16.png" data-src="/media/data/VGG16.png">
                </div>
                <div class="image-caption">VGG16</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Going Deeper with Convolutions</td>
<td style="text-align:center">Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed</td>
<td style="text-align:center">CVPR 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="GoogLeNet" title="" class="post-img b-lazy" href="/media/data/GoogLeNet.png" data-src="/media/data/GoogLeNet.png">
                </div>
                <div class="image-caption">GoogLeNet</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Deep Residual Learning for Image Recognition</td>
<td style="text-align:center">Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun</td>
<td style="text-align:center">CVPR 2016 <em><code>best</code></em></td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">paper</a> <a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="ResNet" title="" class="post-img b-lazy" href="/media/data/ResNet.png" data-src="/media/data/ResNet.png">
                </div>
                <div class="image-caption">ResNet</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Residual Attention Network for Image Classification</td>
<td style="text-align:center">Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang, Xiaogang Wang, Xiaoou Tang</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1704.06904" target="_blank" rel="external">paper</a> <a href="https://github.com/buptwangfei/residual-attention-network" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Res-Attention-Network" title="" class="post-img b-lazy" href="/media/data/Res-Attention-Network.png" data-src="/media/data/Res-Attention-Network.png">
                </div>
                <div class="image-caption">Res-Attention-Network</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Aggregated Residual Transformations for Deep Neural Networks</td>
<td style="text-align:center">Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.05431" target="_blank" rel="external">paper</a> <a href="https://github.com/facebookresearch/ResNeXt" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="ResNeXt" title="" class="post-img b-lazy" href="/media/data/ResNeXt.png" data-src="/media/data/ResNeXt.png">
                </div>
                <div class="image-caption">ResNeXt</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Densely Connected Convolutional Networks</td>
<td style="text-align:center">Gao Huang, Zhuang Liu, Kilian Q. Weinberger</td>
<td style="text-align:center">CVPR 2017 <em><code>best</code></em></td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="external">paper</a> <a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="DenseNet" title="" class="post-img b-lazy" href="/media/data/DenseNet.png" data-src="/media/data/DenseNet.png">
                </div>
                <div class="image-caption">DenseNet</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Deep Pyramidal Residual Networks</td>
<td style="text-align:center">Dongyoon Han, Jiwhan Kim, Junmo Kim</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1610.02915.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/jhkim89/PyramidNet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="PyramidNet" title="" class="post-img b-lazy" href="/media/data/PyramidNet.png" data-src="/media/data/PyramidNet.png">
                </div>
                <div class="image-caption">PyramidNet</div>
            </figure></td>
</tr>
</tbody>
</table>
<h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><h4 id="Must-Read-R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD"><a href="#Must-Read-R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD" class="headerlink" title="Must Read : R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD"></a>Must Read : R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD</h4><table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Authors</th>
<th style="text-align:center">Pub.</th>
<th style="text-align:center">Links</th>
<th style="text-align:center">Figure</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Rich feature hierarchies for accurate object detection and semantic segmentation</td>
<td style="text-align:center">Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik</td>
<td style="text-align:center">CVPR 2014</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/rbgirshick/rcnn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="R-CNN" title="" class="post-img b-lazy" href="/media/data/R-CNN.png" data-src="/media/data/R-CNN.png">
                </div>
                <div class="image-caption">R-CNN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Fast R-CNN</td>
<td style="text-align:center">Ross Girshick</td>
<td style="text-align:center">ICCV 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Fast-R-CNN" title="" class="post-img b-lazy" href="/media/data/Fast-R-CNN.png" data-src="/media/data/Fast-R-CNN.png">
                </div>
                <div class="image-caption">Fast-R-CNN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</td>
<td style="text-align:center">Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>
<td style="text-align:center">TPAMI 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="SPP Net" title="" class="post-img b-lazy" href="/media/data/SPP-Net.png" data-src="/media/data/SPP-Net.png">
                </div>
                <div class="image-caption">SPP Net</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</td>
<td style="text-align:center">Shaoqing Ren, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Ross Girshick, Jian Sun</td>
<td style="text-align:center">NIPS 2015</td>
<td style="text-align:center"><a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external"><code>matlab</code></a> <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external"><code>python</code></a> <a href="https://github.com/longcw/faster_rcnn_pytorch" target="_blank" rel="external"><code>pytorch</code></a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Faster-R-CNN" title="" class="post-img b-lazy" href="/media/data/Faster-R-CNN.png" data-src="/media/data/Faster-R-CNN.png">
                </div>
                <div class="image-caption">Faster-R-CNN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">You Only Look Once: Unified, Real-Time Object Detection</td>
<td style="text-align:center">Joseph Redmon,Santosh Divvala,Ross Girshick, Ali Farhadi</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://arxiv.org/pdf/1506.02640.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="YOLO" title="" class="post-img b-lazy" href="/media/data/YOLO.jpg" data-src="/media/data/YOLO.jpg">
                </div>
                <div class="image-caption">YOLO</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">SSD: Single Shot MultiBox Detector</td>
<td style="text-align:center">Wei Liu1, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://arxiv.org/pdf/1512.02325.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="SSD" title="" class="post-img b-lazy" href="/media/data/SSD.png" data-src="/media/data/SSD.png">
                </div>
                <div class="image-caption">SSD</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Convolutional Feature Masking for Joint Object and Stuff Segmentation</td>
<td style="text-align:center">Jifeng Dai, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Jian Sun</td>
<td style="text-align:center">CVPR 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="CFM" title="" class="post-img b-lazy" href="/media/data/CFM.png" data-src="/media/data/CFM.png">
                </div>
                <div class="image-caption">CFM</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Instance-aware Semantic Segmentation via Multi-task Network Cascades</td>
<td style="text-align:center">Jifeng Dai, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Jian Sun</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Dai_Instance-Aware_Semantic_Segmentation_CVPR_2016_paper.pdf" target="_blank" rel="external">paper</a> <a href="https://github.com/daijifeng001/MNC" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="MNC" title="" class="post-img b-lazy" href="/media/data/MNC.png" data-src="/media/data/MNC.png">
                </div>
                <div class="image-caption">MNC</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">R-FCN: Object Detection via Region-based Fully Convolutional Networks</td>
<td style="text-align:center">Jifeng Dai, Yi Li, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Jian Sun</td>
<td style="text-align:center">NIPS 2016</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1605.06409" target="_blank" rel="external">paper</a> <a href="https://github.com/daijifeng001/R-FCN" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Region-FCN" title="" class="post-img b-lazy" href="/media/data/Region-FCN.png" data-src="/media/data/Region-FCN.png">
                </div>
                <div class="image-caption">Region-FCN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Feature Pyramid Networks for Object Detection</td>
<td style="text-align:center">Tsung-Yi Lin, Piotr Dollár, Ross Girshick, <a href="http://kaiminghe.com/" target="_blank" rel="external">Kaiming He</a>, Bharath Hariharan, and Serge Belongie</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1612.03144.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="FPN" title="" class="post-img b-lazy" href="/media/data/FPN.png" data-src="/media/data/FPN.png">
                </div>
                <div class="image-caption">FPN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Mask R-CNN</td>
<td style="text-align:center">Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick</td>
<td style="text-align:center">ICCV 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Mask-R-CNN" title="" class="post-img b-lazy" href="/media/data/Mask-R-CNN.png" data-src="/media/data/Mask-R-CNN.png">
                </div>
                <div class="image-caption">Mask-R-CNN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</td>
<td style="text-align:center">Xiaolong Wang, Abhinav Shrivastava, Abhinav Gupta</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1704.03414" target="_blank" rel="external">paper</a>  <a href="https://github.com/xiaolonw/adversarial-frcnn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="A-Fast-R-CNN" title="" class="post-img b-lazy" href="/media/data/A-Fast-R-CNN.png" data-src="/media/data/A-Fast-R-CNN.png">
                </div>
                <div class="image-caption">A-Fast-R-CNN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">Multiple Instance Detection Network with Online Instance Classifier Refinement</td>
<td style="text-align:center">Peng Tang, Xinggang Wang, Xiang Bai, Wenyu Liu</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1704.00138" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="MIDN" title="" class="post-img b-lazy" href="/media/data/MIDN.png" data-src="/media/data/MIDN.png">
                </div>
                <div class="image-caption">MIDN</div>
            </figure></td>
</tr>
<tr>
<td style="text-align:center">R-FCN-3000 at 30fps: Decoupling Detection and Classification</td>
<td style="text-align:center">Bharat Singh, Hengdou Li, Abhishek Sharma and Larry S. Davis</td>
<td style="text-align:center">Tech Report</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1712.01802" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="R-FCN-3000" title="" class="post-img b-lazy" href="/media/data/R-FCN-3000.png" data-src="/media/data/R-FCN-3000.png">
                </div>
                <div class="image-caption">R-FCN-3000</div>
            </figure></td>
</tr>
</tbody>
</table>
<h2 id="Semantic-Segmentation-and-Scene-Parsing"><a href="#Semantic-Segmentation-and-Scene-Parsing" class="headerlink" title="Semantic Segmentation and Scene Parsing"></a>Semantic Segmentation and Scene Parsing</h2><h4 id="Must-Read-FCN-Learning-Deconvolution-Network-for-Semantic-Segmentation-U-Net"><a href="#Must-Read-FCN-Learning-Deconvolution-Network-for-Semantic-Segmentation-U-Net" class="headerlink" title="Must Read : FCN, Learning Deconvolution Network for Semantic Segmentation, U-Net"></a>Must Read : FCN, Learning Deconvolution Network for Semantic Segmentation, U-Net</h4><table>
<thead>
<tr>
<th>Title</th>
<th style="text-align:center">Authors</th>
<th style="text-align:center">Pub.</th>
<th style="text-align:center">Links</th>
<th style="text-align:center">Figure</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fully Convolutional Networks for Semantic Segmentation</td>
<td style="text-align:center">Jonathan Long, Evan Shelhamer, Trevor Darrell</td>
<td style="text-align:center">CVPR 2015</td>
<td style="text-align:center"><a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="FCN" title="" class="post-img b-lazy" href="/media/data/FCN.png" data-src="/media/data/FCN.png">
                </div>
                <div class="image-caption">FCN</div>
            </figure></td>
</tr>
<tr>
<td>Learning to Segment Object Candidates</td>
<td style="text-align:center">Pedro O. Pinheiro, Ronan Collobert, Piotr Dollar</td>
<td style="text-align:center">NIPS 2015</td>
<td style="text-align:center"><a href="http://papers.nips.cc/paper/5852-learning-to-segment-object-candidates.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="LSOC" title="" class="post-img b-lazy" href="/media/data/LSOC.png" data-src="/media/data/LSOC.png">
                </div>
                <div class="image-caption">LSOC</div>
            </figure></td>
</tr>
<tr>
<td>Learning to Refine Object Segments</td>
<td style="text-align:center">Pedro O. Pinheiro , Tsung-Yi Lin , Ronan Collobert, Piotr Doll ́ar</td>
<td style="text-align:center">arXiv 1603.08695</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1603.08695.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="LROS" title="" class="post-img b-lazy" href="/media/data/LROS.png" data-src="/media/data/LROS.png">
                </div>
                <div class="image-caption">LROS</div>
            </figure></td>
</tr>
<tr>
<td>Conditional Random Fields as Recurrent Neural Networks</td>
<td style="text-align:center">Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, ZhiZhong Su, Dalong Du, Chang Huang, and Philip H. S. Torr</td>
<td style="text-align:center">ICCV 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zheng_Conditional_Random_Fields_ICCV_2015_paper.html" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="CRFRNN" title="" class="post-img b-lazy" href="/media/data/CRFRNN.png" data-src="/media/data/CRFRNN.png">
                </div>
                <div class="image-caption">CRFRNN</div>
            </figure></td>
</tr>
<tr>
<td>Learning Deconvolution Network for Semantic Segmentation</td>
<td style="text-align:center">Heonwoo Noh, Seunghoon Hong, Bohyung Han</td>
<td style="text-align:center">ICCV 2015</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.html" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="LDN" title="" class="post-img b-lazy" href="/media/data/LDN.png" data-src="/media/data/LDN.png">
                </div>
                <div class="image-caption">LDN</div>
            </figure></td>
</tr>
<tr>
<td>U-Net: Convolutional Networks for Biomedical Image Segmentation</td>
<td style="text-align:center">Olaf Ronneberger, Philipp Fischer, Thomas Brox</td>
<td style="text-align:center">MICCAI 2015</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="U-Net" title="" class="post-img b-lazy" href="/media/data/U-Net.png" data-src="/media/data/U-Net.png">
                </div>
                <div class="image-caption">U-Net</div>
            </figure></td>
</tr>
<tr>
<td>Instance-sensitive Fully Convolutional Networks</td>
<td style="text-align:center">Jifeng Dai, Kaiming He, Yi Li, Shaoqing Ren, Jian Sun</td>
<td style="text-align:center">ECCV 2016</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1603.08678" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="ISFCN" title="" class="post-img b-lazy" href="/media/data/ISFCN.png" data-src="/media/data/ISFCN.png">
                </div>
                <div class="image-caption">ISFCN</div>
            </figure></td>
</tr>
<tr>
<td>Laplacian Pyramid Reconstruction and Refinement for Semantic Segmentation</td>
<td style="text-align:center">Golnaz Ghiasi, Charless C. Fowlkes</td>
<td style="text-align:center">ECCV 2016</td>
<td style="text-align:center"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_32" target="_blank" rel="external">paper</a>  <a href="https://github.com/golnazghiasi/LRR" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="LPRR" title="" class="post-img b-lazy" href="/media/data/LPRR.png" data-src="/media/data/LPRR.png">
                </div>
                <div class="image-caption">LPRR</div>
            </figure></td>
</tr>
<tr>
<td>Attention to Scale: Scale-aware Semantic Image Segmentation</td>
<td style="text-align:center">Liang-Chieh Chen, Yi Yang, Jiang Wang, Wei Xu</td>
<td style="text-align:center">CVPR 2016</td>
<td style="text-align:center"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Chen_Attention_to_Scale_CVPR_2016_paper.html" target="_blank" rel="external">paper</a> <a href="http://liangchiehchen.com/projects/DeepLab.html" target="_blank" rel="external"><code>DeepLab</code></a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Attention-to-scale" title="" class="post-img b-lazy" href="/media/data/Attention-to-scale.png" data-src="/media/data/Attention-to-scale.png">
                </div>
                <div class="image-caption">Attention-to-scale</div>
            </figure></td>
</tr>
<tr>
<td>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</td>
<td style="text-align:center">Guosheng Lin, Anton Milan, Chunhua Shen, Ian Reid</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">paper</a>  <a href="https://github.com/guosheng/refinenet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="RefineNet" title="" class="post-img b-lazy" href="/media/data/RefineNet.png" data-src="/media/data/RefineNet.png">
                </div>
                <div class="image-caption">RefineNet</div>
            </figure></td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>Pyramid Scene Parsing Network</td>
<td style="text-align:center">Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="external">paper</a>  <a href="https://github.com/hszhao/PSPNet" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="PSPNet" title="" class="post-img b-lazy" href="/media/data/PSPNet.png" data-src="/media/data/PSPNet.png">
                </div>
                <div class="image-caption">PSPNet</div>
            </figure></td>
</tr>
<tr>
<td>ICNet for Real-Time Semantic Segmentation on High-Resolution Images</td>
<td style="text-align:center">Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, Jiaya Jia</td>
<td style="text-align:center">Tech Report</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="ICNet" title="" class="post-img b-lazy" href="/media/data/ICNet.png" data-src="/media/data/ICNet.png">
                </div>
                <div class="image-caption">ICNet</div>
            </figure></td>
</tr>
<tr>
<td>Dilated Residual Networks</td>
<td style="text-align:center">Fisher Yu, Vladlen Koltun, Thomas Funkhouser</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1705.09914" target="_blank" rel="external">paper</a> <a href="https://github.com/fyu/drn" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="DRN" title="" class="post-img b-lazy" href="/media/data/DRN.png" data-src="/media/data/DRN.png">
                </div>
                <div class="image-caption">DRN</div>
            </figure></td>
</tr>
<tr>
<td>Fully Convolutional Instance-aware Semantic Segmentation</td>
<td style="text-align:center">Yi Li, Haozhi Qi, Jifeng Dai, Xiangyang Ji, Yichen Wei</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.07709" target="_blank" rel="external">paper</a> <a href="https://github.com/msracver/FCIS" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="FCIS" title="" class="post-img b-lazy" href="/media/data/FCIS.png" data-src="/media/data/FCIS.png">
                </div>
                <div class="image-caption">FCIS</div>
            </figure></td>
</tr>
<tr>
<td>Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes</td>
<td style="text-align:center">Tobias Pohlen, Alexander Hermans, Markus Mathias, Bastian Leibe</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1611.08323" target="_blank" rel="external">paper</a> <a href="https://github.com/TobyPDE/FRRN" target="_blank" rel="external">github</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="FRRN" title="" class="post-img b-lazy" href="/media/data/FRRN.png" data-src="/media/data/FRRN.png">
                </div>
                <div class="image-caption">FRRN</div>
            </figure></td>
</tr>
<tr>
<td>Object Region Mining with Adversarial Erasing: A Simple Classification toSemantic Segmentation Approach</td>
<td style="text-align:center">Yunchao Wei, Jiashi Feng, Xiaodan Liang, Ming-Ming Cheng, Yao Zhao, Shuicheng Yan</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1703.08448" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="A-Erasing" title="" class="post-img b-lazy" href="/media/data/A-Erasing.png" data-src="/media/data/A-Erasing.png">
                </div>
                <div class="image-caption">A-Erasing</div>
            </figure></td>
</tr>
<tr>
<td>Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade</td>
<td style="text-align:center">Xiaoxiao Li, Ziwei Liu, Ping Luo, Chen Change Loy, Xiaoou Tang</td>
<td style="text-align:center">CVPR 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1704.01344.pdf" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Not-All-Pixels-Are-Equal" title="" class="post-img b-lazy" href="/media/data/Not-All-Pixels-Are-Equal.png" data-src="/media/data/Not-All-Pixels-Are-Equal.png">
                </div>
                <div class="image-caption">Not-All-Pixels-Are-Equal</div>
            </figure></td>
</tr>
<tr>
<td>Semantic Segmentation with Reverse Attention</td>
<td style="text-align:center">Qin Huang, Chunyang Xia, Wuchi Hao, Siyang Li, Ye Wang, Yuhang Song and C.-C. Jay Kuo</td>
<td style="text-align:center">BMVC 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1707.06426" target="_blank" rel="external">paper</a> <a href="https://drive.google.com/drive/folders/0By2w_AaM8Rzbllnc3JCQjhHYnM?usp=sharing" target="_blank" rel="external"><code>code</code></a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Rev-Attention" title="" class="post-img b-lazy" href="/media/data/Rev-Attention.png" data-src="/media/data/Rev-Attention.png">
                </div>
                <div class="image-caption">Rev-Attention</div>
            </figure></td>
</tr>
<tr>
<td>Predicting Deeper into the Future of Semantic Segmentation</td>
<td style="text-align:center">Pauline Luc, Natalia Neverova, Camille Couprie, Jakob Verbeek and Yann LeCun</td>
<td style="text-align:center">ICCV 2017</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1703.07684" target="_blank" rel="external">paper</a> <a href="https://thoth.inrialpes.fr/people/pluc/iccv2017" target="_blank" rel="external"><code>project page</code></a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Deeper-into-Future" title="" class="post-img b-lazy" href="/media/data/Deeper-into-Future.png" data-src="/media/data/Deeper-into-Future.png">
                </div>
                <div class="image-caption">Deeper-into-Future</div>
            </figure></td>
</tr>
<tr>
<td>Learning to Segment Every Thing</td>
<td style="text-align:center">Ronghang Hu, Piotr Dollar, Kaiming He, Trevor Darrell, Ross Girshick</td>
<td style="text-align:center">Tech Report</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1711.10370" target="_blank" rel="external">paper</a></td>
<td style="text-align:center"><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img alt="Seg-Everything" title="" class="post-img b-lazy" href="/media/data/Seg-Everything.png" data-src="/media/data/Seg-Everything.png">
                </div>
                <div class="image-caption">Seg-Everything</div>
            </figure></td>
</tr>
</tbody>
</table>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><ul>
<li>Dropout- A Simple Way to Prevent Neural Networks from Overfitting</li>
<li>Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift</li>
</ul>
<h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><ul>
<li>Generating Sequences With Recurrent Neural Networks</li>
<li>Word embedding</li>
<li>Distributed Representations of Words and Phrases and their Compositionality</li>
</ul>
<h2 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h2><p>Show and Tell: A Neural Image Caption Generator<br>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</p>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
                    </li>
                    
                    <li>
                        <a href="/tags/Computer-Vision/" rel="tag"># Computer Vision</a>
                    </li>
                    
                    <li>
                        <a href="/tags/Paper-List/" rel="tag"># Paper List</a>
                    </li>
                    
                    <li>
                        <a href="/tags/Self-Study/" rel="tag"># Self-Study</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="Multiple Object Tracking Summary" href="/2018/01/10/Multiple-Object-Tracking-Summary/">
            ← Multiple Object Tracking Summary
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="Person re-ID Summary" href="/2018/01/02/person_re-ID_summary/">
            Person re-ID Summary →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Classification"><span class="toc-text">Image Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Must-Read-LeNet-AlexNet-VGG-16-GoogleNet-ResNet"><span class="toc-text">Must Read : LeNet, AlexNet, VGG-16, GoogleNet, ResNet</span></a></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Detection"><span class="toc-text">Object Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Must-Read-R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD"><span class="toc-text">Must Read : R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Semantic-Segmentation-and-Scene-Parsing"><span class="toc-text">Semantic Segmentation and Scene Parsing</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Must-Read-FCN-Learning-Deconvolution-Network-for-Semantic-Segmentation-U-Net"><span class="toc-text">Must Read : FCN, Learning Deconvolution Network for Semantic Segmentation, U-Net</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Regularization"><span class="toc-text">Regularization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RNN"><span class="toc-text">RNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-captioning"><span class="toc-text">Image captioning</span></a></li>
    </div>
</div>



	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(https://i.loli.net/2017/11/26/5a19c56faa29f.jpg)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; world4jason &mdash;</small>
    <h3 class="read-next-card-header-title">最新文章</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2018/06/04/Mask-RCNN-Code-Reading-DetectionLayer/">Mask RCNNCode Reading - Detection Layer</a>
      </li>
      
      
      
      <li>
        <a href="/2018/06/04/Batch-Normalization-and-Group-Normalization/">Batch Normalization and Group Normalization</a>
      </li>
      
      
      
      <li>
        <a href="/2018/06/03/Mask-RCNN-Code-Reading-ROI_Align/">Mask RCNNCode Reading for ROI Align Layer</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(https://i.loli.net/2017/11/26/5a19c56faa29f.jpg)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">分類</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code/">Code</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Detection/">Detection</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GAN/">GAN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Github/">Github</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MOT/">MOT</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Model-Architecture/">Model Architecture</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Model-Architecture/Classification/">Classification</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Optimize/">Optimize</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Re-ID/">Re-ID</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Segmentation/">Segmentation</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Segmentation/Detection/">Detection</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Series/">Series</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Series/Segmentation/">Segmentation</a></li></ul></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(https://i.loli.net/2017/11/26/5a19c56faa29f.jpg)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">標籤雲</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/C/" style="font-size: 14px;">C++</a> <a href="/tags/CNN/" style="font-size: 22.33px;">CNN</a> <a href="/tags/CPP/" style="font-size: 14px;">CPP</a> <a href="/tags/Classification/" style="font-size: 15.67px;">Classification</a> <a href="/tags/Computer-Vision/" style="font-size: 19px;">Computer Vision</a> <a href="/tags/Convolution/" style="font-size: 17.33px;">Convolution</a> <a href="/tags/Courses/" style="font-size: 14px;">Courses</a> <a href="/tags/Deep-Learning/" style="font-size: 24px;">Deep Learning</a> <a href="/tags/GAN/" style="font-size: 19px;">GAN</a> <a href="/tags/Generation/" style="font-size: 19px;">Generation</a> <a href="/tags/Generative-Model/" style="font-size: 19px;">Generative Model</a> <a href="/tags/MOT/" style="font-size: 15.67px;">MOT</a> <a href="/tags/Model-Architecture/" style="font-size: 17.33px;">Model Architecture</a> <a href="/tags/Model-Compression/" style="font-size: 14px;">Model Compression</a> <a href="/tags/Object-Detection/" style="font-size: 17.33px;">Object Detection</a> <a href="/tags/Paper-List/" style="font-size: 14px;">Paper List</a> <a href="/tags/Pose-Estimation/" style="font-size: 15.67px;">Pose Estimation</a> <a href="/tags/R-CNN/" style="font-size: 20.67px;">R-CNN</a> <a href="/tags/Segmentation/" style="font-size: 19px;">Segmentation</a> <a href="/tags/Self-Study/" style="font-size: 15.67px;">Self-Study</a> <a href="/tags/Style-Transfer/" style="font-size: 14px;">Style Transfer</a> <a href="/tags/Summary/" style="font-size: 14px;">Summary</a> <a href="/tags/Tensorflow/" style="font-size: 14px;">Tensorflow</a> <a href="/tags/Tracking/" style="font-size: 17.33px;">Tracking</a> <a href="/tags/code/" style="font-size: 17.33px;">code</a> <a href="/tags/image-retrieval/" style="font-size: 14px;">image retrieval</a> <a href="/tags/python/" style="font-size: 14px;">python</a> <a href="/tags/real-time/" style="font-size: 15.67px;">real-time</a> <a href="/tags/survey/" style="font-size: 14px;">survey</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <img class="search-overlay-logo" src="https://i.loli.net/2017/11/26/5a19c0b50432e.png" alt="world4jason">
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="搜尋 ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="world4jason">world4jason</a>
			&copy; 2019
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="external noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="external noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>if(window.navigator && navigator.serviceWorker) {navigator.serviceWorker.getRegistrations().then(function(registrations) {for(let registration of registrations) {registration.unregister()}})}</script>


<script async src="/js/allinone.min.js" id="scriptLoad"></script>






<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        var bLazy = new Blazy()
    })
</script>







<script src="/js/lightgallery.min.js"></script>
<link rel="stylesheet" href="/css/lightgallery.min.css">
<script>
    lightGallery(document.getElementById('lightgallery'), {
        selector: '.post-img'
    });
</script>




<script async src="https://cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script async src="https://unpkg.com/valine@1.3.4/dist/Valine.min.js"></script>
<script>
    window.addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true,
        })
    });
</script>





<script>
    document.getElementById('scriptLoad').addEventListener('load', function(){
        searchFunc("/")
    });
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->






</body>
</html>
