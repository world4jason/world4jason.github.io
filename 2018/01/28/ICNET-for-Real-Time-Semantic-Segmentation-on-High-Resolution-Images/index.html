<!DOCTYPE html>
<html>
<head>
    

    

    



    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    
    
    <title>ICNET for Real-Time Semantic Segmentation on High-Resolution Images | world4jason | 菜鳥搬磚日常</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Deep Learning,Computer Vision,Segmentation,real-time">
    <meta name="description" content="RecapQuote:其實很討厭這作者的paper效果都很好, 但是每次都是用matlab, 而且PSPNet作者還說training code因為公司問題不能發布, 傻眼                                                                                                          https://">
<meta name="keywords" content="Deep Learning,Computer Vision,Segmentation,real-time">
<meta property="og:type" content="article">
<meta property="og:title" content="ICNET for Real-Time Semantic Segmentation on High-Resolution Images">
<meta property="og:url" content="https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/index.html">
<meta property="og:site_name" content="world4jason">
<meta property="og:description" content="RecapQuote:其實很討厭這作者的paper效果都很好, 但是每次都是用matlab, 而且PSPNet作者還說training code因為公司問題不能發布, 傻眼                                                                                                          https://">
<meta property="og:locale" content="zh-TW">
<meta property="og:image" content="https://world4jason.github.io/media/15172367977860.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172162210529.png">
<meta property="og:image" content="https://world4jason.github.io/media/15172351270369.png">
<meta property="og:image" content="https://world4jason.github.io/media/15172353341447.png">
<meta property="og:image" content="https://world4jason.github.io/media/15172758974357.png">
<meta property="og:image" content="https://world4jason.github.io/media/15172822508697.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172765679435.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172417899356.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172417973947.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172418178955.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172418074043.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/20161024115403020.gif">
<meta property="og:image" content="https://world4jason.github.io/media/15172789125366.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172790446136.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172790496567.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172794424801.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15172827737568.png">
<meta property="og:image" content="https://world4jason.github.io/media/15172838466580.png">
<meta property="og:image" content="https://world4jason.github.io/media/15172845289475.jpg">
<meta property="og:updated_time" content="2018-01-30T04:21:13.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ICNET for Real-Time Semantic Segmentation on High-Resolution Images">
<meta name="twitter:description" content="RecapQuote:其實很討厭這作者的paper效果都很好, 但是每次都是用matlab, 而且PSPNet作者還說training code因為公司問題不能發布, 傻眼                                                                                                          https://">
<meta name="twitter:image" content="https://world4jason.github.io/media/15172367977860.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="world4jason" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Jason Yeh</h5>
          <a href="mailto:world4jason@gmail.com" title="world4jason@gmail.com" class="mail">world4jason@gmail.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-Home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/world4jason" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/research"  >
                <i class="icon icon-lg icon-research"></i>
                Research
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-about"></i>
                About
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/cv"  >
                <i class="icon icon-lg icon-CV"></i>
                CV
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">ICNET for Real-Time Semantic Segmentation on High-Resolution Images</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="搜尋">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">ICNET for Real-Time Semantic Segmentation on High-Resolution Images</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-01-28T08:50:31.000Z" itemprop="datePublished" class="page-time">
  2018-01-28
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Segmentation/">Segmentation</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Recap"><span class="post-toc-number">1.</span> <span class="post-toc-text">Recap</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Speed-Analysis"><span class="post-toc-number">2.</span> <span class="post-toc-text">Speed Analysis</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Intuitive-Speedup"><span class="post-toc-number">3.</span> <span class="post-toc-text">Intuitive Speedup</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#加速方法-1-輸入向下採樣-Downsampling-Input"><span class="post-toc-number">3.0.1.</span> <span class="post-toc-text">加速方法 1: 輸入向下採樣(Downsampling Input)</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#加速方法-2-利用較小的feature-map來做inference-Downsampling-Feature"><span class="post-toc-number">3.0.2.</span> <span class="post-toc-text">加速方法 2 : 利用較小的feature map來做inference(Downsampling Feature)</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#加速方法-3-減少模型複雜度-Model-Compression"><span class="post-toc-number">3.0.3.</span> <span class="post-toc-text">加速方法 3 : 減少模型複雜度(Model Compression)</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#FCN-Fully-Convolutional-Networks-for-Fully-Convolutional-Networks"><span class="post-toc-number">3.0.4.</span> <span class="post-toc-text">FCN:Fully Convolutional Networks for Fully Convolutional Networks</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Step-1"><span class="post-toc-number">3.0.4.1.</span> <span class="post-toc-text">Step 1:</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Step-2"><span class="post-toc-number">3.0.4.2.</span> <span class="post-toc-text">Step 2:</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Step-3"><span class="post-toc-number">3.0.4.3.</span> <span class="post-toc-text">Step 3:</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Step-4"><span class="post-toc-number">3.0.4.4.</span> <span class="post-toc-text">Step 4:</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Upsampling"><span class="post-toc-number">3.0.4.5.</span> <span class="post-toc-text">Upsampling</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Skip-Architecture"><span class="post-toc-number">3.0.4.6.</span> <span class="post-toc-text">Skip Architecture</span></a></li></ol></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Architecture"><span class="post-toc-number">4.</span> <span class="post-toc-text">Architecture</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Cascade-Feature-Fusion"><span class="post-toc-number">5.</span> <span class="post-toc-text">Cascade Feature Fusion</span></a></li></ol>
        </nav>
    </aside>
    
<article id="post-ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">ICNET for Real-Time Semantic Segmentation on High-Resolution Images</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-01-28 16:50:31" datetime="2018-01-28T08:50:31.000Z"  itemprop="datePublished">2018-01-28</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Segmentation/">Segmentation</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h2 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h2><p>Quote:<br>其實很討厭這作者的paper<br>效果都很好, 但是每次都是用matlab, 而且PSPNet作者還說training code因為公司問題不能發布, 傻眼<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172367977860.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br><a href="https://www.zhihu.com/question/53356671" target="_blank" rel="external">https://www.zhihu.com/question/53356671</a></p>
<p>Paper<br><a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1704.08545.pdf</a><br>Code<br><a href="https://github.com/hszhao/ICNet" target="_blank" rel="external">https://github.com/hszhao/ICNet</a><br><a href="https://github.com/aitorzip/Keras-ICNet" target="_blank" rel="external">https://github.com/aitorzip/Keras-ICNet</a><br><a href="https://github.com/hellochick/ICNet-tensorflow" target="_blank" rel="external">https://github.com/hellochick/ICNet-tensorflow</a></p>
<p>Key Difference<br>之前的那些方法，如FCN、SegNet、UNet、RefineNet等，用高解析度圖片當input以後，強調Single scale或是Multi Scale在不同層之間的特徵融合，所有的Data需要在整個網絡中運行，因為高解析度的輸入而導致了昂貴的計算費用.而本文的方法，使用低解析度圖片作為主要輸入，採用高解析度圖片進行refine，保留細節的同時減少了開銷.</p>
<p>##Abstract</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">We</span> propose an compressed-PSPNet-<span class="keyword">based </span>image cascade network (ICNet) that incorporates <span class="keyword">multi-resolution </span><span class="keyword">branches </span>under proper label guidance to <span class="keyword">address </span>this challenge.</div></pre></td></tr></table></figure>
<p>ICNet是一個基於PSPNet的real-time semantic segmentation network，論文內對PSPNet做深入的分析，並且找出影響inference speed*的缺點。並且用搭配multi-resolution cascade combination。</p>
<p>*註:inference speed是單指DeConv的階段。</p>
<p>##Introduction</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172162210529.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在論文發表的時刻(2017 March), CityScapes上所有的Model表現基本上分成兩種類型, 一種是擁有高精準度但速度不行, 另一種是速度快但精准度不行。此論文在PSPNet的基礎上來增進速度，並找一個速度跟精準度的平衡點。</p>
<p>論文貢獻:</p>
<ul>
<li>可以在1024x2048的解析度下保持30 fps的計算速度(Tensorflow版本實測可行, 但要去掉preproccess部分)</li>
<li>相對PSPNet來說, 可疑提高5倍速度並可以減少五倍RAM消耗</li>
<li>低解析的速度+高解析的細節做cascade的整合</li>
</ul>
<h2 id="Speed-Analysis"><a href="#Speed-Analysis" class="headerlink" title="Speed Analysis"></a>Speed Analysis</h2><p>從PSPNet做解析<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172351270369.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br>藍色是1024x2048, 綠色是512x1024 (1/4大小)<br>從上圖可知</p>
<ul>
<li>圖越大速度越慢</li>
<li>網路寬度越大速度越慢</li>
<li>Kernel越多速度越慢, 以圖中例子來說stage4跟stage5在解析同樣的input時, inference speed差距十分驚人, 因為這部分的kernel number差距了一倍。</li>
</ul>
<h2 id="Intuitive-Speedup"><a href="#Intuitive-Speedup" class="headerlink" title="Intuitive Speedup"></a>Intuitive Speedup</h2><h4 id="加速方法-1-輸入向下採樣-Downsampling-Input"><a href="#加速方法-1-輸入向下採樣-Downsampling-Input" class="headerlink" title="加速方法 1: 輸入向下採樣(Downsampling Input)"></a>加速方法 1: 輸入向下採樣(Downsampling Input)</h4><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172353341447.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在resolution只有原本的0.5跟0.25的狀況下雖然速度變快但精准度如上圖所示可以看出效果很差。</p>
<h4 id="加速方法-2-利用較小的feature-map來做inference-Downsampling-Feature"><a href="#加速方法-2-利用較小的feature-map來做inference-Downsampling-Feature" class="headerlink" title="加速方法 2 : 利用較小的feature map來做inference(Downsampling Feature)"></a>加速方法 2 : 利用較小的feature map來做inference(Downsampling Feature)</h4><p>FCN Downsampling到32倍, Deep Lab到 8倍, 而用作者之前的PSPNet50, 縮小到了1:8, 1:16, 1:32整理的Table, 但可以看到最快的速度也只有132ms, 不太能符合real-time的標準。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172758974357.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h4 id="加速方法-3-減少模型複雜度-Model-Compression"><a href="#加速方法-3-減少模型複雜度-Model-Compression" class="headerlink" title="加速方法 3 : 減少模型複雜度(Model Compression)"></a>加速方法 3 : 減少模型複雜度(Model Compression)</h4><p>採用了其他篇paper(Pruning filters for efficient convnets)，作法就是減少Filter數量, 但一樣差強人意<br> <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172822508697.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h4 id="FCN-Fully-Convolutional-Networks-for-Fully-Convolutional-Networks"><a href="#FCN-Fully-Convolutional-Networks-for-Fully-Convolutional-Networks" class="headerlink" title="FCN:Fully Convolutional Networks for Fully Convolutional Networks"></a>FCN:Fully Convolutional Networks for Fully Convolutional Networks</h4><p>這裡額外多講一下FCN，算是CNN做semantic segmentation的始祖，本質上的區別大概就是…FCN是沒有全連結層的CNN，好處是可以接受任意大小輸入。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172765679435.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>CNN要如何轉FCN? 以此篇paper為例，input是一個224x224x3的圖，經過一系列Conv跟Downsampling之後是7x7x512。<br>AlexNet使用了兩個4096的全連接層，最後一個有1000個神經元的全連接層用於計算分類評分。我們可以將這3個全連接層轉化為Convolution層。</p>
<p>任一全連結層轉化為Conv的方式以以下為例：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">例如 K=<span class="number">4096</span> 的全連接層，輸入是<span class="number">7</span>x7x512，這個全連接層可以被等效地看做一個F=<span class="number">7</span>,Padding=<span class="number">0</span>,Stride=<span class="number">1</span>,Filter Number=<span class="number">4096</span> 的Conv層。換句話說，就是將Filter Size設置的和Input Data Size一致了。輸出將變成 <span class="number">1</span>x1x4096，這個結果就和使用初始的那個全連接層一樣了。</div></pre></td></tr></table></figure></p>
<p>針對第一個連接區域是[7x7x512]的全連接層，令其Filter Size為F=7<strong>（Filter Size為7x7）</strong>，這樣輸出為[1x1x4096]。<br>針對第二個全連接層，令其Filter Size為F=1<strong>（Filter Size為1x1）</strong>，這樣輸出為[1x1x4096]。<br>對最後一個全連接層也做類似的，令其F=1<strong>（Filter Size為1x1）</strong>，最終輸出為[1x1x1000]</p>
<h5 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1:"></a>Step 1:</h5><p>下圖是是原始CNN結構，CNN中輸入的圖像大小是統一固定resize成227x227大小的圖像，第一層pooling後為55x55，第二層pooling後為27x27，第五層pooling後的圖像大小為13*13。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172417899356.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h5 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2:"></a>Step 2:</h5><p>FCN輸入的圖像是假設是H*W，第一層pooling後變為原圖大小的1/4，第二層變為的1/8，第五層變為1/ 16，第八層變為1/32<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172417973947.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h5 id="Step-3"><a href="#Step-3" class="headerlink" title="Step 3:"></a>Step 3:</h5><p>Convolution本質上就是DownSampling（下採樣）。經過多次Convolution和pooling以後，得到的圖像越來越小，解析度越來越低。其中圖像到H/32∗W/32 的時候圖片是最小的一層時，所產生圖叫做heatmap，heatmap就是我們最重要的高維特徵圖，得到高維特徵的heatmap之後就是最重要的一步也是最後的一步，就是對此heatmap進行UpSampling(Deconvolution)，把圖像進行放大到原圖像的大小。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172418178955.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h5 id="Step-4"><a href="#Step-4" class="headerlink" title="Step 4:"></a>Step 4:</h5><p>最後的輸出是1000張heatmap經過UpSampling變為原圖大小的圖片。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172418074043.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h5 id="Upsampling"><a href="#Upsampling" class="headerlink" title="Upsampling"></a>Upsampling</h5><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/20161024115403020.gif" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>其實這篇paper內雖然叫做Deconvolution，但之前CS231n課程內的大神也有說到，叫做Transposed Convolution比較適合。<br>舉個例子來說：</p>
<p>4x4的圖片輸入，Filter Size為3x3, 沒有Padding / Stride, 則輸出為2x2。</p>
<p>輸入矩陣可展開為16維向量，記作<em>x</em><br>輸出矩陣可展開為4維向量，記作<em>y</em><br>Convolution運算可表示為<em>y</em>=<em>Cx</em><br>C其實就是如下的稀疏陣，而Forwarding就改成了的矩陣運算<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172789125366.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br>BackPropagation的話，假若已經從更深的網路得到了</p>
<p><center><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172790446136.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></center><br>那麼就可以導出以下公式:<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172790496567.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br>Deconvolution其實就是Forwarding時乘CT，而BackPropagation時乘(CT)T，即C。總結來說，Deconvolution等於Convolution在神經網絡結構的正向和反向傳播中的計算，做相反的計算。</p>
<h5 id="Skip-Architecture"><a href="#Skip-Architecture" class="headerlink" title="Skip Architecture"></a>Skip Architecture</h5><p>由於縮小32倍結果超糟糕，所以FCN在前面的Pooling Layer進行Upsampling，然後結合這些結果來優化輸出。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172794424801.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>總結一下前面速度分析的結果，一系列的優化方法：</p>
<ul>
<li>Downsampling Input：降低輸入解析度能都大幅度的加速，但同時會讓預測非常模糊</li>
<li>Downsampling Feature：可以加速但同時會降低準確率</li>
<li>Model Compression：壓縮訓練好的模型，通過減輕模型達到加速效果，可惜實驗效果不佳</li>
</ul>
<p>針對以上的分析，發現，低解析度的圖片能夠有效降低運行時間，但是失去很多細節，而且邊界模糊；但是高解析度的計算時間難以忍受，ICNet總結了上述幾個問題，提出了一個綜合性的方法：使用低解析度加速捕捉語義，使用高解析度獲取細節，使用特徵融合(CFF)結合，同時使用guide label來監督，在限制的時間內獲得有效的結果。</p>
<p><img src="/media/15172827737568.png" alt=""></p>
<p>圖中用了原尺寸,1/2尺寸,1/4尺寸當input，低解析度分枝超过50层，提取更多的语义信息(inference 18 ms)，中解析度分枝有17层conv，但是由于权重共享，只有inference 6ms，而高解析度分枝是3 conv，有inference 9ms.<br>与其他网络的不同 </p>
<table>
<thead>
<tr>
<th style="text-align:center">分枝</th>
<th>過程</th>
<th>耗時</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">低解析</td>
<td>在中解析度的1/16輸出的基礎上，再縮放到1/32.經過Convolution後，然後使用幾個dilated convolution擴展接受野但不縮小尺寸，最終以原圖的1/32大小輸出feature map。</td>
<td>雖然層數較多，但是解析度低，速度快，且與分枝二共享一部分權重，耗時為18 ms</td>
</tr>
<tr>
<td style="text-align:center">中解析</td>
<td>以原圖的1/2的解析度作為輸入，經過Convolution後以1/8縮放，得到原圖的1/16大小feature map，再將低解析度分枝的輸出feature map通過CFF(cascade feature fusion )單元相融合得到最終輸出。值得注意的是：低解析度和中解析度的捲積參數是共享的。</td>
<td>有17個Convolution層，與分枝一共享一部分權重，與分枝一一起一共耗時6ms</td>
</tr>
<tr>
<td style="text-align:center">高解析</td>
<td>原圖輸入，經過Convolution後以1/8縮放，得到原圖的1/8大小的feature map，再將中解析度處理後的輸出通過CFF單元融合</td>
<td>有3個卷積層，雖然解析度高，因為少，耗時為9ms</td>
</tr>
</tbody>
</table>
<p>對於每個分枝的輸出特徵，首先會上採樣2倍做輸出，在訓練的時候，會以Ground truth的1/16、1/8/、1/4來指導各個分枝的訓練，這樣的輔助訓練使得梯度優化更為平滑，便於訓練收斂，隨著每個分枝學習能力的增強，預測沒有被任何一個分枝主導。利用這樣的漸變的特徵融合和級聯引導結構可以產生合理的預測結果。</p>
<p>ICNet使用低解析度完成語義分割，使用高解析度幫助細化結果。在結構上，產生的feature大大減少，同時仍然保持必要的細節。</p>
<p>不同分枝的預測效果如下:<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15172838466580.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>可以看到第三個分枝輸出效果無疑是最好的。在測試時，只保留第三分枝的結果。</p>
<h2 id="Cascade-Feature-Fusion"><a href="#Cascade-Feature-Fusion" class="headerlink" title="Cascade Feature Fusion"></a>Cascade Feature Fusion</h2><p><img src="/media/15172845289475.jpg" alt=""><br>圖中的Loss是輔助Loss,F1是較低解析的分枝, F2是較高解析的分枝，</p>
<p>L=λ1L1+λ2L2+λ3L3</p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        
<span class="post-time">
    最後更新時間：<time datetime="2018-01-30T04:21:13.000Z" itemprop="dateUpdated">2018-01-30 12:21:13</time>
</span><br>


        
    </div>
    <footer>
        <a href="https://world4jason.github.io">
            <img src="/img/avatar.jpg" alt="Jason Yeh">
            Jason Yeh
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Vision/">Computer Vision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Segmentation/">Segmentation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/real-time/">real-time</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/&title=《ICNET for Real-Time Semantic Segmentation on High-Resolution Images》 — world4jason&pic=https://world4jason.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/&title=《ICNET for Real-Time Semantic Segmentation on High-Resolution Images》 — world4jason&source=菜鳥搬磚日常" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《ICNET for Real-Time Semantic Segmentation on High-Resolution Images》 — world4jason&url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/&via=https://world4jason.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/01/14/Distance/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">機器學習中的相似性度量</h4>
      </a>
    </div>
  
</nav>



    


<section class="comments" id="comments">
    <div id="disqus_thread"></div>
    <script>
    var disqus_shortname = 'true';
    lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>




<section class="comments" id="comments">
    <!-- UY BEGIN -->
    <div id="uyan_frame"></div>
    <script src="http://v2.uyan.cc/code/uyan.js?uid=true"></script>
    <!-- UY END -->
</section>




<section class="comments" id="comments">
    <div id="gitment_thread"></div>
    <link rel="stylesheet" href="//unpkg.com/gitment/style/default.css">
    <script src="//unpkg.com/gitment/dist/gitment.browser.js"></script>
    <script>
        var gitment = new Gitment({
            owner: '',
            repo: '',
            oauth: {
                client_id: '',
                client_secret: '',
            },
        })
        gitment.render('comments')
    </script>
</section>




</article>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        總訪客數：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        總訪問量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>本部落格係採用<a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh_TW">創用 CC 姓名標示 4.0 國際 授權條款授權</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Jason Yeh &copy; 2015 - 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/&title=《ICNET for Real-Time Semantic Segmentation on High-Resolution Images》 — world4jason&pic=https://world4jason.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/&title=《ICNET for Real-Time Semantic Segmentation on High-Resolution Images》 — world4jason&source=菜鳥搬磚日常" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《ICNET for Real-Time Semantic Segmentation on High-Resolution Images》 — world4jason&url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/&via=https://world4jason.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=https://world4jason.github.io/2018/01/28/ICNET-for-Real-Time-Semantic-Segmentation-on-High-Resolution-Images/" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '持續搬磚中';
            clearTimeout(titleTime);
        } else {
            document.title = '(つェ⊂)咦!又回來了!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



</body>
</html>
