<!DOCTYPE html>
<html>
<head>
    

    

    



    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    
    
    <title>Person re-ID 綜述 | world4jason | 菜鳥搬磚日常</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    
    <meta name="keywords" content="tracking,image retrieval,survey">
    <meta name="description" content="目標難度 目標遮擋（Occlusion）導致部分特徵丟失 不同的 View，Illumination 導致同一目標的特徵差異 不同目標衣服顏色近似、特徵近似導致區分度下降  解決方案1.">
<meta name="keywords" content="tracking,image retrieval,survey">
<meta property="og:type" content="article">
<meta property="og:title" content="Person re-ID 綜述">
<meta property="og:url" content="https://world4jason.github.io/2018/01/02/person_re-ID_summary/index.html">
<meta property="og:site_name" content="world4jason">
<meta property="og:description" content="目標難度 目標遮擋（Occlusion）導致部分特徵丟失 不同的 View，Illumination 導致同一目標的特徵差異 不同目標衣服顏色近似、特徵近似導致區分度下降  解決方案1.">
<meta property="og:locale" content="zh-TW">
<meta property="og:image" content="https://world4jason.github.io/media/15149820234945.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150472221676.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150474384428.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150477657739.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150479915859.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150480384222.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150481401848.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150485085441.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150485782017.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150487793131.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150488009610.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150491105798.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150492644360.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150490021821.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150490274695.jpg">
<meta property="og:image" content="https://world4jason.github.io/media/15150495642066.jpg">
<meta property="og:updated_time" content="2018-01-04T10:02:59.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Person re-ID 綜述">
<meta name="twitter:description" content="目標難度 目標遮擋（Occlusion）導致部分特徵丟失 不同的 View，Illumination 導致同一目標的特徵差異 不同目標衣服顏色近似、特徵近似導致區分度下降  解決方案1.">
<meta name="twitter:image" content="https://world4jason.github.io/media/15149820234945.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="world4jason" href="/atom.xml">
    
    <link rel="shortcut icon" href="/">
    <link rel="stylesheet" href="/css/style.css?v=1.6.17">
    <script>window.lazyScripts=[]</script>

    <!-- custom head --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

    <aside id="menu"  >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Jason Yeh</h5>
          <a href="mailto:undefined" class="mail">
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Person re-ID 綜述</div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Person re-ID 綜述</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-01-02T13:50:49.000Z" itemprop="datePublished" class="page-time">
  2018-01-02
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Re-ID/">Re-ID</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
<article id="post-person_re-ID_summary"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Person re-ID 綜述</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-01-02 21:50:49" datetime="2018-01-02T13:50:49.000Z"  itemprop="datePublished">2018-01-02</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Re-ID/">Re-ID</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15149820234945.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="目標"><a href="#目標" class="headerlink" title="目標"></a>目標</h2><h2 id="難度"><a href="#難度" class="headerlink" title="難度"></a>難度</h2><ol>
<li>目標遮擋（Occlusion）導致部分特徵丟失</li>
<li>不同的 View，Illumination 導致同一目標的特徵差異</li>
<li>不同目標衣服顏色近似、特徵近似導致區分度下降</li>
</ol>
<h2 id="解決方案"><a href="#解決方案" class="headerlink" title="解決方案"></a>解決方案</h2><h3 id="1-Representation-learning-ReID"><a href="#1-Representation-learning-ReID" class="headerlink" title="1. Representation learning + ReID"></a>1. Representation learning + ReID</h3><p>看做分類(Classification/Identification)問題或者驗證(Verification)問題：<br>(1) 分類問題是指利用行人的ID或者屬性等作為訓練標籤來訓練模型；<br>(2) 驗證問題是指輸入一對（兩張）行人圖片，讓網絡來學習這兩張圖片是否屬於同一個行人。</p>
<p>Classification/Identification loss和verification loss</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150472221676.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>額外改進方向[2]是在加上許多行人的label，像是性別、頭髮以及服裝等等。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150474384428.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h3 id="2-Metric-learning-ReID"><a href="#2-Metric-learning-ReID" class="headerlink" title="2. Metric learning + ReID"></a>2. Metric learning + ReID</h3><p>常用於圖像檢索的方法，通過網絡學習出兩張圖片的相似度。<br>(Contrastive loss)[5]、三元組損失(Triplet loss)、 四元組損失(Quadruplet loss)、難樣本採樣三元組損失(Triplet hard loss with batch hard mining, TriHard loss)、邊界挖掘損失(Margin sample mining loss, MSML</p>
<p>Contrastive loss 基本上就是Siamese CNN<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150477657739.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>訓練時是三個正樣本一個副樣本，test時未知<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150479915859.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150480384222.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h3 id="3-Local-Feature-ReID"><a href="#3-Local-Feature-ReID" class="headerlink" title="3. Local Feature + ReID"></a>3. Local Feature + ReID</h3><p>論文[3]用local feature而不用global feature，切割好以後送到LSTM去學<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150481401848.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>但論文[3]會有對齊問題，所以論文[4]用pose跟skeleton來做姿勢預測，再通過仿射變換對齊</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150485085441.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>論文[5]直接拿關節點切出ROI，14個人體關節點，得到7個ROI區域，(頭、上身、下身和四肢)<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150485782017.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h3 id="4-Video-Sequence-ReID"><a href="#4-Video-Sequence-ReID" class="headerlink" title="4. Video Sequence + ReID"></a>4. Video Sequence + ReID</h3><p>這方向不熟 貼兩張圖參考參考而已<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150487793131.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150488009610.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h3 id="5-GAN-ReID"><a href="#5-GAN-ReID" class="headerlink" title="5. GAN + ReID"></a>5. GAN + ReID</h3><p>ReID數據集目前最大的也只有幾千個ID，跟萬張圖片而已，CNN based還容易overfitting<br>GAN主要是用在遷移學習跟基於條件的生成</p>
<p>第一篇就是ICCV2017的論文[5]以及後來同作者改進的論文[6]，是可以避免overfitting但生成效果就很慘<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150491105798.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>為了處理不同數據集，甚至是不同camera所造成bias的問題，論文[7]是利用cycleGAN based的設計，利用遷移學習來處理兩個數同數據集的問題，先切割分前景跟背景，在轉換過去。<br>D有兩個loss(還是有兩個D不確定，paper內沒架構圖)一個是前景的絕對誤差loss，一個是正常的判別器loss。判別器loss是用來判斷生成的圖屬於哪個domain，前景的loss是為了保證行人前景儘可能逼真不變。mask用PSPnet來找的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150492644360.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Pose Normalization[8]<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150490021821.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150490274695.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/media/15150495642066.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h2 id="資料種類"><a href="#資料種類" class="headerlink" title="資料種類"></a>資料種類</h2><ul>
<li>Video-based</li>
<li>Image-based</li>
<li>Long-term activity</li>
<li>Individual action </li>
</ul>
<h2 id="資料庫"><a href="#資料庫" class="headerlink" title="資料庫"></a>資料庫</h2><p><a href="http://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html" target="_blank" rel="external">Robust Systems Lab</a></p>
<h2 id="程式碼"><a href="#程式碼" class="headerlink" title="程式碼"></a>程式碼</h2><p><a href="https://zhuanlan.zhihu.com/p/32585203" target="_blank" rel="external">简单行人重识别代码到88%准确率</a><br><a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="external">https://github.com/layumi/Person_reID_baseline_pytorch</a></p>
<ul>
<li><h3 id="ICCV-2017"><a href="#ICCV-2017" class="headerlink" title="ICCV 2017"></a>ICCV 2017</h3><ul>
<li><a href="https://github.com/KovenYu/CAMEL" target="_blank" rel="external">Cross-view Asymmetric Metric Learning for Unsupervised Re-id </a></li>
<li><a href="https://github.com/zlmzju/part_reid" target="_blank" rel="external">Deeply-Learned Part-Aligned Representations for Person Re-Identification </a></li>
<li><a href="https://github.com/VisualComputingInstitute/triplet-reid" target="_blank" rel="external">In Defense of the Triplet Loss for Person Re-Identification </a></li>
<li><a href="https://github.com/shuangjiexu/Spatial-Temporal-Pooling-Networks-ReID" target="_blank" rel="external">Jointly Attentive Spatial-Temporal Pooling Networks for Video-based Person Re-Identification</a></li>
<li><a href="http://github.com/syfafterzy/SVDNet-for-Pedestrian-Retrieval" target="_blank" rel="external">SVDNet for Pedestrian Retrieval</a></li>
<li><a href="http://github.com/layumi/Person-reID_GAN" target="_blank" rel="external">Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro</a></li>
</ul>
</li>
</ul>
<ul>
<li><h3 id="CVPR-2017"><a href="#CVPR-2017" class="headerlink" title="CVPR 2017"></a>CVPR 2017</h3><ul>
<li><a href="http://github.com/yokattame/SpindleNet" target="_blank" rel="external">Spindle Net: Person Re-Identification With Human Body Region Guided Feature Decomposition and Fusion</a></li>
<li><a href="http://github.com/liangzheng06/PRW-baseline" target="_blank" rel="external">Person Re-Identification in the Wild</a> </li>
<li><a href="http://github.com/ShuangLI59/person_search" target="_blank" rel="external">Joint Detection and Identification Feature Learning for Person Search</a></li>
<li><a href="http//github.com/sciencefans/Quality-Aware-Network">Quality Aware Network for Set to Set Recognition</a></li>
</ul>
</li>
</ul>
<h2 id="Paper-List"><a href="#Paper-List" class="headerlink" title="Paper List"></a>Paper List</h2><pre><code>- Point to Set Similarity Based Deep Feature Learning for Person Re-Identification
- Fast Person Re-Identification via Cross-Camera Semantic Binary Transformation
- See the Forest for the Trees: Joint Spatial and Temporal Recurrent Neural Networks for Video-Based Person Re-Identification
- Learning Deep Context-Aware Features Over Body and Latent Parts for Person Re-Identification
- Consistent-Aware Deep Learning for Person Re-Identification in a Camera Network
- Re-Ranking Person Re-Identification With k-Reciprocal Encoding
- Multiple People Tracking by Lifted Multicut and Person Re-Identification
</code></pre><p>[1] Mengyue Geng, Yaowei Wang, Tao Xiang, Yonghong Tian. Deep transfer learning for person reidentification[J]. arXiv preprint arXiv:1611.05244, 2016.</p>
<p>[2] Yutian Lin, Liang Zheng, Zhedong Zheng, YuWu, Yi Yang. Improving person re-identification by attribute and identity learning[J]. arXiv preprint arXiv:1703.07220, 2017.</p>
<p>[3] Rahul Rama Varior, Bing Shuai, Jiwen Lu, Dong Xu, Gang Wang. A siamese long short-term memory architecture for human re-identification[C]//European Conference on Computer Vision. Springer, 2016:135–153.</p>
<p>[4]Liang Zheng, Yujia Huang, Huchuan Lu, Yi Yang. Pose invariant embedding for deep person reidentification[J]. arXiv preprint arXiv:1701.07732, 2017.</p>
<p>[5] Zheng Z, Zheng L, Yang Y. Unlabeled samples generated by gan improve the person re-identification baseline in vitro[J]. arXiv preprint arXiv:1701.07717, 2017.</p>
<p>[6] Zhong Z, Zheng L, Zheng Z, et al. Camera Style Adaptation for Person Re-identification[J]. arXiv preprint arXiv:1711.10295, 2017.</p>
<p>[7] Wei L, Zhang S, Gao W, et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification[J]. arXiv preprint arXiv:1711.08565, 2017.</p>
<p>[8] Qian X, Fu Y, Wang W, et al. Pose-Normalized Image Generation for Person Re-identification[J]. arXiv preprint arXiv:1712.02225, 2017.</p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        

        
    </div>
    <footer>
        <a href="https://world4jason.github.io">
            <img src="/" alt="Jason Yeh">
            Jason Yeh
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/image-retrieval/">image retrieval</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/survey/">survey</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tracking/">tracking</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2017/12/24/PYTHON中如何使用-ARGS和-KWARGS/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">PYTHON中如何使用*ARGS和**KWARGS</h4>
      </a>
    </div>
  
</nav>



    


<section class="comments" id="comments">
    <div id="disqus_thread"></div>
    <script>
    var disqus_shortname = 'world4jason';
    lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>










</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>本部落格係採用<a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh_TW">創用 CC 姓名標示 4.0 國際 授權條款授權</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Jason Yeh &copy; 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: , REWARD: false };


</script>

<script src="/js/main.min.js?v=1.6.17"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</body>
</html>
